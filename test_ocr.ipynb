{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f953ee2",
   "metadata": {},
   "source": [
    "## simple pdf to img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12bb783",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb pymupdf pillow gemma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30105b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81244631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF for PDF -> images\n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "\n",
    "class PDFImageExtractor:\n",
    "    \"\"\"Convert PDF pages to images and manage temporary image folder.\"\"\"\n",
    "\n",
    "    def __init__(self, pdf_path, output_folder=\"pdf_images\"):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "    def pdf_to_images(self):\n",
    "        \"\"\"Convert each page of PDF to JPG image and return paths.\"\"\"\n",
    "        doc = fitz.open(self.pdf_path)\n",
    "        if not os.path.exists(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "\n",
    "        image_paths = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap(dpi=200)  \n",
    "            image_path = os.path.join(self.output_folder, f\"page_{page_num + 1}.jpg\")\n",
    "            pix.save(image_path)\n",
    "            image_paths.append(image_path)\n",
    "            print(f\"âœ… Page {page_num + 1} saved as {image_path}\")\n",
    "        doc.close()\n",
    "        return image_paths\n",
    "\n",
    "    def cleanup_images(self):\n",
    "        \"\"\"Delete all images from the output folder after extraction.\"\"\"\n",
    "        if os.path.exists(self.output_folder):\n",
    "            shutil.rmtree(self.output_folder)\n",
    "            print(f\"ğŸ—‘ï¸ Deleted temporary folder: {self.output_folder}\")\n",
    "\n",
    "\n",
    "class GemmaOCR:\n",
    "    \"\"\"Send images to Gemma3 model via Ollama API to extract text.\"\"\"\n",
    "\n",
    "    def __init__(self, model=\"gemma3:12b\", ollama_url=\"http://localhost:11434/api/generate\"):\n",
    "        self.model = model\n",
    "        self.ollama_url = ollama_url\n",
    "\n",
    "    def encode_image(self, image_path):\n",
    "        \"\"\"Convert image file to base64 string.\"\"\"\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    def extract_text_from_image(self, image_path):\n",
    "        \"\"\"Send image to Gemma3 for OCR-like extraction.\"\"\"\n",
    "        image_b64 = self.encode_image(image_path)\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": \"Extract and return all readable text from this image.\",\n",
    "            \"images\": [image_b64]\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            \n",
    "            response = requests.post(self.ollama_url, json=payload, stream=True)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"âš ï¸ Ollama API error {response.status_code}: {response.text}\")\n",
    "                return \"\"\n",
    "\n",
    "            extracted_text = \"\"\n",
    "            for line in response.iter_lines():\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    data = json.loads(line.decode(\"utf-8\"))\n",
    "                    extracted_text += data.get(\"response\") or data.get(\"content\") or \"\"\n",
    "                except json.JSONDecodeError:\n",
    "                    continue  # skip malformed lines\n",
    "\n",
    "            return extracted_text.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error extracting text from image: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "def process_pdf_with_gemma(pdf_path):\n",
    "    \"\"\"Full pipeline: PDF -> images -> Gemma OCR -> combined text.\"\"\"\n",
    "    extractor = PDFImageExtractor(pdf_path)\n",
    "    gemma_ocr = GemmaOCR()\n",
    "\n",
    "    image_paths = extractor.pdf_to_images()\n",
    "    all_text = \"\"\n",
    "\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        print(f\"\\nğŸ” Processing Page {idx + 1}...\")\n",
    "        page_text = gemma_ocr.extract_text_from_image(image_path)\n",
    "        all_text += f\"\\n\\n--- Page {idx + 1} ---\\n{page_text}\"\n",
    "\n",
    "    \n",
    "    extractor.cleanup_images()\n",
    "    return all_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"./New folder/Return Policy.pdf\"  # Update this to your PDF path\n",
    "    output_text = process_pdf_with_gemma(pdf_path)\n",
    "\n",
    "   \n",
    "    base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    output_file = f\"{base_name}.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output_text)\n",
    "\n",
    "    print(f\"\\nâœ… Extraction Complete! Text saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe0c12",
   "metadata": {},
   "source": [
    "## easy ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28254170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing EasyOCR...\n",
      "EasyOCR initialized successfully!\n",
      "Step 1: Converting PDF to images...\n",
      "Converting 7 pages to images...\n",
      "Page 1 converted to image\n",
      "Page 2 converted to image\n",
      "Page 3 converted to image\n",
      "Page 4 converted to image\n",
      "Page 5 converted to image\n",
      "Page 6 converted to image\n",
      "Page 7 converted to image\n",
      "Step 2: Extracting text from images...\n",
      "Processing page 1/7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Busra\\Melikoz\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 2/7...\n",
      "Processing page 3/7...\n",
      "Processing page 4/7...\n",
      "Processing page 5/7...\n",
      "Processing page 6/7...\n",
      "Processing page 7/7...\n",
      "Processing completed successfully!\n",
      "\n",
      "==================================================\n",
      "EXTRACTION RESULTS\n",
      "==================================================\n",
      "Total pages processed: 7\n",
      "\n",
      "Extracted Text:\n",
      "------------------------------\n",
      "8/25/25,5.19 PM Calmly Writer Online 1 Introduction This privacy policy describes the personal data that Shopify processes (which may include collecting, organizing, structuring, storing, using, or disclosing) when you use or access Shopify Consumer Services, or when you interact with a merchant that is powered by Shopify's platform (\"Shopify Merchants\" or \"Merchants\") . If any provisions in this policy conflict with provisions of any other Shopify privacy policy, the provisions in this policy will apply: 2. What Personal Data We Receive Personal Data is any information from or about an identified or identifiable person; but does not include aggregated or anonymized information. We receive the following types of Personal Data when you interact with Shopify, Shopify Merchants, and/or use the Shopify Consumer Services: 1. Profile and Contact Information: We receive contact or other account profile information when you sign up for or interact with Shopify Consumer Services, which may include name; shipping address, email address, profile picture; or other information you choose to provide us. We may link this information to the different devices or accounts you use when you interact with Shopify, Shopify Merchants, and/or use the Shopify Consumer Services 2. Device Information: We receive information about the computers, phones, and other devices you use to interact with Shopify, Shopify Merchants, and/or the Shopify Consumer Services, including IP address (which may be used to determine general location) , device identifiers, cookie IDs, the browser you use, your network connection; or other unique identifiers or device information: 3. Payment Information: We may receive payment information when you use Shop or make a purchase through Shopify or Shopify Merchants, such as your payment card number and expiration date 4. Use of Shopify apps and services: We receive information regarding your use of or interactions with our apps and services, whether or not you are logged in to Shopify, such as your interactions with Shopify Merchants in the Shop app, the shop(s) you visit and purchase from, the products you view and purchase, the product reviews and ratings you post and share, your order history, the purchases where you use https:Ilwwwcalmlywriter comlonlinel 1/7 Pay\n",
      "\n",
      "--- Page Break ---\n",
      "\n",
      "8/25/25,5.19 PM Calmly Writer Online Shop your search queries; favorited shops and other activities related to the Shopify Consumer Services: 5. Activity with Shopify Merchants: When you browse or shop with Shopify Merchants, we receive information about your activity on the Shopify Merchant site, including information about your browsing and search activity, the products and services yoU place in your cart and/or purchase; your billing and shipping information, transaction details and your payment information. 6_ Settings and Privacy Preferences: We receive information about your settings and preferences on Shopify and our Merchants, as well as information about your browser and device privacy settings: 7 . Communications with Shopify: We receive information, including message and email content; when you communicate with Shopify (such as for customer support inquiries, taking surveys, participating in promotions or research): 8. Social Network Accounts: If you choose to link, connect; or login to Shopify Consumer Services through a third party online service, you direct the service to send us certain information about you controlled by that service, such as profile information. This sharing is subject to the applicable privacy notices and your privacy settings of that service 9. Email and Shopping Service Integrations: We receive information from email messages in the inboxes that you connect to your Shop account; and information from email messages you transfer to the Shop app to be included in your order history: We do not use this information for advertising or marketing purposes: 3. How We Use Your Personal Data Shopify uses Personal Data for the following purposes depending on how you interact with which Shopify services you use, Merchants you visit; and based on your activity across all devices where you log in to or interact with Shopify, Shopify Merchants, and/or use the Shopify Consumer Services: 1. Provide, Improve, and Customize Shopify services: To provide customized Shopify services to you, including by displaying your purchase history and order status in one place, providing easy payment options when you shop, recommending and customizing the products and Merchants featured for you, and to improve Shopify services, including based on your use of Shopify Consumer Services and activity with our Merchant(s): https:Ilwwwcalmlywriter comlonlinel 217 Pay; uS,\n",
      "\n",
      "--- Page Break ---\n",
      "\n",
      "8/25/25,5.19 PM Calmly Writer Online 2. Track and Implement Your Settings and Privacy Preferences: To track and implement your settings and privacy preferences with Shopify and our Merchants. 3. Perform Product Research and Development: To develop, test; and improve Shopify services, including troubleshooting our products and services, developing new or improved Shopify services, and analyzing your use of and interactions with Shopify services and with Shopify Merchants 4_ Advertise; Market and Promote Shopify and Shopify Merchants: To market, advertise; and promote Shopify and Shopify Merchants on and off Shopify, including for personalized communications or advertisements relating to Shopify and Shopify Merchants on third-party services You can opt-out of our use of your Personal Data to show you marketing and advertisements based on your interaction with different Shopify Merchants here: 5. Communicate with You: To communicate with you about Shopify services and your transactions, including about product updates, your account, and changes to our policies and terms. We also use your information to respond to you when you contact uS. 6. a secure payment and shopping experience, and to detect; investigate, and prevent malicious conduct; fraudulent activity or unsafe experiences, address security threats, protect public safety, and secure Shopify Services for you and our Merchants: 7. Legal Reasons: To comply with applicable law or respond to valid legal process, including requests from law enforcement or government agencies; to investigate or participate in civil discovery, litigation; or other adversarial legal proceedings, and to enforce or investigate potential violations of our terms or policies When Shopify processes your Personal Data from Merchants you interact or shop with in order to help Merchants run their Stores and to provide business services to our Merchants, we are acting at the direction of the Merchant; and the Merchants' terms of service and privacy policy apply-not Shopifys. For more information about how Merchants collect and use Personal Data when you visit and make purchases in their Stores, review the Merchant's terms and privacy policy: 4. Third-Parties Who Receive Personal Data https:Ilwwwcalmlywriter comlonlinel 3/7 May\n",
      "\n",
      "--- Page Break ---\n",
      "\n",
      "8/25/25,5.19 PM Calmly Writer Online Depending on which Shopify services you use or interact with and Merchants you visit; Shopify may provide Personal Data to the following categories of third parties or in the following circumstances: 1. Vendors: Shopify works with third-party service providers to provide, support; and improve Shopify services and technical infrastructure; for business services, such as payment processing, including in relation to purchases made when you use Shopify services, and for marketing and business analytics. 2. Marketing, Advertising, and Analytics Partners: We may use third-party marketing; advertising, and analytics partners to deliver personalized advertising and to help uS understand how people use or interact with Shopify services and our Merchants: These partners may receive information about your use of, or interactions with, Shopify services and our Merchants, including through third-party cookies or other technologies For example; we may make information available to third-party advertising companies to serve you with relevant ads or content and to manage, improve and measure our advertising campaigns Providing information to certain third parties for advertising services may be considered \"sharing\" or \"targeted advertising;\" as defined by certain privacy laws that may apply in your jurisdiction. You can opt-out of our sharing of your Personal Data for targeted advertising here: 3. Change of Control: We may share Personal Data with actual or prospective acquirers, their representatives and other relevant participants in, or during negotiations of,any sale, merger acquisition, restructuring, or change in control involving all or a portion of Shopifys business or assets, including in connection with bankruptcy or similar proceedings. 4. Legal Reasons: We may share Personal Data as needed to: (1) comply with applicable law or respond to, investigate; or participate in valid legal process and proceedings, including from law enforcement or government agencies; (2) enforce or investigate potential violations of our terms or policies; (3) detect; prevent; or investigate potential fraud, abuse, or safety and security concerns, including threats to the public; (4) meet our corporate and social responsibility commitments; (5) protect our and our Merchants and users' rights and property; and (6) resolve disputes and enforce agreements 5. Sharing at Your Discretion: Where you provide consent; we share your Personal Data as described at the time of consent, such as when connecting with a third party application or website: https:Ilwwwcalmlywriter comlonlinel 4/7\n",
      "\n",
      "--- Page Break ---\n",
      "\n",
      "8/25/25,5.19 PM Calmly Writer Online 5. Third Party Partners & Integrations Parts of Shopify services may link to third party services. Shopify doesntt own or control these third parties. When you interact with these third parties and choose to use their services, your use is subject to the privacy policies of those providers. 6. Your Privacy Rights and Choices You may have certain rights to manage your Personal Data depending on where you live. To exercise any privacy rights available to you, please visit our privacy_portal: Depending on your jurisdiction, the following rights may apply, subject to certain exceptions: 1. Access and Portability: Right to request access to your Personal Data. 2. Correction Rectification: Right to correct inaccurate or incomplete Personal Data in certain circumstances: 3. Deletion Erasure: Right to delete Personal Data about you: 4. Right to opt out of Sharing or Targeted Advertising: Right to direct us not to share your Personal Data with third parties for targeted advertising or to use information about your interactions with Shopify Merchants to show you targeted advertisements and marketing: To opt-out of having your Personal Data used for these purposes, visit our privacy_portal: Data subjects who are subject to the data protection laws of the European Economic Area, If you are a Shop app user; you can also update your account information or request to delete your account directly through your in-app settings You may have additional rights with Shopify Merchants. For information and any choices related to how an individual Merchant enables Shopify to use your data, see that Merchant's website and policies Retention We retain Personal Data for as as we have an ongoing business need to do so (e.g,, to provide the Shopify services to you and our Merchants, to comply with applicable legal, tax, or accounting requirements, for security and fraud detection or prevention; or in connection https:Ilwwwcalmlywriter comlonlinel long\n",
      "\n",
      "--- Page Break ---\n",
      "\n",
      "8/25/25, 5.19 PM Calmly Writer Online with backup or disaster recovery processes), unless a different retention period is permitted or required by applicable law: The criteria used to determine our retention periods include the following: 1. The length of time we and our Merchants have an ongoing relationship with you and provide Shopify services to you (for example, for as long as you have an account with us or keep using our services or services offered by our Merchants); 2. Whether you modify or delete your information through your accounts; 3. Whether Shopify has a legal obligation to keep the data (for example, certain laws require Shopify to keep records of your transactions for a certain period of time); or 4. Whether retention is advisable in light of our legal position (such as in regard to the enforcement of our agreements, the resolution of disputes, the applicable statutes of limitations; litigation, or regulatory investigation): 8. How to Contact Us To exercise your rights, please visit our privacy_portal: For questions or concerns related to this Privacy Policy, you may contact us by visiting our overalLprivacy_policy under How you can reach uS.\" 9. Changes to this Privacy Policy We may update this Privacy Policy periodically to account for changes in our processing of Personal Data, and we will post the updated Privacy Policy on our website, with a \"Last Updated\" date at the top. 10. European Data Subjects This section 10 applies if the processing of your Personal Data is subject to the data protection laws of the European Economic Area, the UK, or Switzerland. 1. Our legal basis for processing your Personal Data: Our legal basis for processing your Personal Data to show you targeted advertisements is your consent: For information about our legal basis for other processing described in this Privacy Policy, please refer to our overalLprivacy_policy: https:Ilwwwcalmlywriter comlonlinel\n",
      "\n",
      "--- Page Break ---\n",
      "\n",
      "8/25/25,5.19 PM Calmly Writer Online 2. Your rights in relation to your Personal Data: In addition to the rights noted in Section 6 above, you can exercise the following rights: 3. Objection to Processing and Restriction of Processing: Right to object to the processing of your Personal Data for certain purposes and to request the restriction of the processing of your Personal Data: 4. Withdrawal of Consent: Right to withdraw consent where processing of your Personal Data is based on consent: If you withdraw your consent; this will not affect the lawfulness of any processing based on your consent before its withdrawal: https:Ilwwwcalmlywriter comlonlinel\n",
      "\n",
      "Extracted text saved to: extracted_text.txt\n",
      "\n",
      "==================================================\n",
      "PAGE-WISE DETAILS\n",
      "==================================================\n",
      "\n",
      "Page 1:\n",
      "Text: 8/25/25,5.19 PM Calmly Writer Online 1 Introduction This privacy policy describes the personal data that Shopify processes (which may include collecting, organizing, structuring, storing, using, or di...\n",
      "\n",
      "Page 2:\n",
      "Text: 8/25/25,5.19 PM Calmly Writer Online Shop your search queries; favorited shops and other activities related to the Shopify Consumer Services: 5. Activity with Shopify Merchants: When you browse or sho...\n",
      "\n",
      "Page 3:\n",
      "Text: 8/25/25,5.19 PM Calmly Writer Online 2. Track and Implement Your Settings and Privacy Preferences: To track and implement your settings and privacy preferences with Shopify and our Merchants. 3. Perfo...\n",
      "\n",
      "Page 4:\n",
      "Text: 8/25/25,5.19 PM Calmly Writer Online Depending on which Shopify services you use or interact with and Merchants you visit; Shopify may provide Personal Data to the following categories of third partie...\n",
      "\n",
      "Page 5:\n",
      "Text: 8/25/25,5.19 PM Calmly Writer Online 5. Third Party Partners & Integrations Parts of Shopify services may link to third party services. Shopify doesntt own or control these third parties. When you int...\n",
      "\n",
      "Page 6:\n",
      "Text: 8/25/25, 5.19 PM Calmly Writer Online with backup or disaster recovery processes), unless a different retention period is permitted or required by applicable law: The criteria used to determine our re...\n",
      "\n",
      "Page 7:\n",
      "Text: 8/25/25,5.19 PM Calmly Writer Online 2. Your rights in relation to your Personal Data: In addition to the rights noted in Section 6 above, you can exercise the following rights: 3. Objection to Proces...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nInstallation requirements:\\npip install easyocr PyMuPDF pillow opencv-python numpy\\n\\nUsage:\\n1. Install the required packages\\n2. Replace 'sample_document.pdf' with your PDF path\\n3. Run the script\\n4. The extracted text will be saved to 'extracted_text.txt'\\n\\nFeatures:\\n- Converts PDF pages to high-resolution images\\n- Enhances images for better OCR accuracy\\n- Extracts text with confidence scores\\n- Filters results by confidence threshold\\n- Supports multiple languages\\n- Saves extracted text to file\\n- Option to keep or cleanup temporary image files\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#easy ocr from claude 1st attempt\n",
    "import easyocr\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "import cv2\n",
    "\n",
    "class PDFOCRProcessor:\n",
    "    def __init__(self, languages=['en'], gpu=False):\n",
    "        \"\"\"\n",
    "        Initialize the PDF OCR processor\n",
    "        \n",
    "        Args:\n",
    "            languages (list): List of languages for OCR (e.g., ['en', 'es'])\n",
    "            gpu (bool): Whether to use GPU for OCR processing\n",
    "        \"\"\"\n",
    "        print(\"Initializing EasyOCR...\")\n",
    "        self.reader = easyocr.Reader(languages, gpu=gpu)\n",
    "        print(\"EasyOCR initialized successfully!\")\n",
    "    \n",
    "    def pdf_to_images(self, pdf_path: str, output_dir: str = None, dpi: int = 200) -> List[str]:\n",
    "        \"\"\"\n",
    "        Convert PDF pages to images\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            output_dir (str): Directory to save images (optional)\n",
    "            dpi (int): DPI for image conversion (higher = better quality)\n",
    "            \n",
    "        Returns:\n",
    "            List[str]: List of image file paths\n",
    "        \"\"\"\n",
    "        if not os.path.exists(pdf_path):\n",
    "            raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "        \n",
    "        # Create output directory if specified\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Open PDF\n",
    "        doc = fitz.open(pdf_path)\n",
    "        image_paths = []\n",
    "        \n",
    "        print(f\"Converting {len(doc)} pages to images...\")\n",
    "        \n",
    "        for page_num in range(len(doc)):\n",
    "            \n",
    "            page = doc[page_num]\n",
    "            \n",
    "            \n",
    "            mat = fitz.Matrix(dpi/72, dpi/72)\n",
    "            \n",
    "            \n",
    "            pix = page.get_pixmap(matrix=mat)\n",
    "            \n",
    "            \n",
    "            img_data = pix.tobytes(\"png\")\n",
    "            img = Image.open(io.BytesIO(img_data)) if 'io' in globals() else None\n",
    "            \n",
    "            \n",
    "            if img is None:\n",
    "                img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            \n",
    "            if output_dir:\n",
    "                image_path = os.path.join(output_dir, f\"page_{page_num + 1}.png\")\n",
    "                img.save(image_path, \"PNG\")\n",
    "                image_paths.append(image_path)\n",
    "            else:\n",
    "                \n",
    "                image_path = f\"temp_page_{page_num + 1}.png\"\n",
    "                img.save(image_path, \"PNG\")\n",
    "                image_paths.append(image_path)\n",
    "            \n",
    "            print(f\"Page {page_num + 1} converted to image\")\n",
    "        \n",
    "        doc.close()\n",
    "        return image_paths\n",
    "    \n",
    "    def enhance_image_for_ocr(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Enhance image quality for better OCR results\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Enhanced image array\n",
    "        \"\"\"\n",
    "        \n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        \n",
    "        denoised = cv2.fastNlMeansDenoising(gray)\n",
    "        \n",
    "        \n",
    "        thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                       cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        return thresh\n",
    "    \n",
    "    def extract_text_from_image(self, image_path: str, enhance: bool = True) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Extract text from image using EasyOCR\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file\n",
    "            enhance (bool): Whether to enhance image before OCR\n",
    "            \n",
    "        Returns:\n",
    "            List[Tuple[str, float]]: List of (text, confidence) tuples\n",
    "        \"\"\"\n",
    "        if enhance:\n",
    "            \n",
    "            img = self.enhance_image_for_ocr(image_path)\n",
    "            results = self.reader.readtext(img)\n",
    "        else:\n",
    "            \n",
    "            results = self.reader.readtext(image_path)\n",
    "        \n",
    "        \n",
    "        text_results = []\n",
    "        for result in results:\n",
    "            text = result[1]\n",
    "            confidence = result[2]\n",
    "            text_results.append((text, confidence))\n",
    "        \n",
    "        return text_results\n",
    "    \n",
    "    def process_pdf(self, pdf_path: str, output_dir: str = None, \n",
    "                   enhance_images: bool = True, confidence_threshold: float = 0.5,\n",
    "                   cleanup_temp: bool = True) -> dict:\n",
    "        \"\"\"\n",
    "        Complete pipeline: PDF -> Images -> OCR\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            output_dir (str): Directory to save images (optional)\n",
    "            enhance_images (bool): Whether to enhance images for OCR\n",
    "            confidence_threshold (float): Minimum confidence for text extraction\n",
    "            cleanup_temp (bool): Whether to cleanup temporary image files\n",
    "            \n",
    "        Returns:\n",
    "            dict: Results containing text from each page\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'pdf_path': pdf_path,\n",
    "            'pages': [],\n",
    "            'total_pages': 0,\n",
    "            'extracted_text': ''\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            print(\"Step 1: Converting PDF to images...\")\n",
    "            image_paths = self.pdf_to_images(pdf_path, output_dir)\n",
    "            results['total_pages'] = len(image_paths)\n",
    "            \n",
    "            \n",
    "            print(\"Step 2: Extracting text from images...\")\n",
    "            all_text = []\n",
    "            \n",
    "            for i, image_path in enumerate(image_paths):\n",
    "                print(f\"Processing page {i + 1}/{len(image_paths)}...\")\n",
    "                \n",
    "                \n",
    "                text_results = self.extract_text_from_image(image_path, enhance_images)\n",
    "                \n",
    "                \n",
    "                filtered_text = [text for text, conf in text_results if conf >= confidence_threshold]\n",
    "                \n",
    "                page_text = ' '.join(filtered_text)\n",
    "                all_text.append(page_text)\n",
    "                \n",
    "                page_info = {\n",
    "                    'page_number': i + 1,\n",
    "                    'image_path': image_path,\n",
    "                    'text': page_text,\n",
    "                    'raw_results': text_results\n",
    "                }\n",
    "                results['pages'].append(page_info)\n",
    "            \n",
    "            \n",
    "            results['extracted_text'] = '\\n\\n--- Page Break ---\\n\\n'.join(all_text)\n",
    "            \n",
    "            \n",
    "            if cleanup_temp and not output_dir:\n",
    "                for image_path in image_paths:\n",
    "                    if os.path.exists(image_path) and image_path.startswith('temp_'):\n",
    "                        os.remove(image_path)\n",
    "                        print(f\"Cleaned up temporary file: {image_path}\")\n",
    "            \n",
    "            print(\"Processing completed successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during processing: {str(e)}\")\n",
    "            results['error'] = str(e)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the PDFOCRProcessor\n",
    "    \"\"\"\n",
    "    \n",
    "    processor = PDFOCRProcessor(languages=['en'], gpu=False)\n",
    "    \n",
    "    \n",
    "    pdf_path = \"./New folder/privacy_policy.pdf\"  \n",
    "    \n",
    "    # Optional: specify output directory for images\n",
    "    output_dir = \"extracted_images\"  # Set to None to use temporary files\n",
    "    \n",
    "    # Process the PDF\n",
    "    results = processor.process_pdf(\n",
    "        pdf_path=pdf_path,\n",
    "        output_dir=output_dir,\n",
    "        enhance_images=True,\n",
    "        confidence_threshold=0.5,\n",
    "        cleanup_temp=True\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    if 'error' not in results:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"EXTRACTION RESULTS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Total pages processed: {results['total_pages']}\")\n",
    "        print(f\"\\nExtracted Text:\\n{'-'*30}\")\n",
    "        print(results['extracted_text'])\n",
    "        \n",
    "        # Save extracted text to file\n",
    "        with open('extracted_text.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(results['extracted_text'])\n",
    "        print(f\"\\nExtracted text saved to: extracted_text.txt\")\n",
    "        \n",
    "        # Print page-wise details\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"PAGE-WISE DETAILS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        for page in results['pages']:\n",
    "            print(f\"\\nPage {page['page_number']}:\")\n",
    "            print(f\"Text: {page['text'][:200]}...\" if len(page['text']) > 200 else f\"Text: {page['text']}\")\n",
    "    else:\n",
    "        print(f\"Error occurred: {results['error']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Import required libraries check\n",
    "    try:\n",
    "        import io\n",
    "    except ImportError:\n",
    "        import io\n",
    "    \n",
    "    main()\n",
    "\n",
    "\"\"\"\n",
    "Installation requirements:\n",
    "pip install easyocr PyMuPDF pillow opencv-python numpy\n",
    "\n",
    "Usage:\n",
    "1. Install the required packages\n",
    "2. Replace 'sample_document.pdf' with your PDF path\n",
    "3. Run the script\n",
    "4. The extracted text will be saved to 'extracted_text.txt'\n",
    "\n",
    "Features:\n",
    "- Converts PDF pages to high-resolution images\n",
    "- Enhances images for better OCR accuracy\n",
    "- Extracts text with confidence scores\n",
    "- Filters results by confidence threshold\n",
    "- Supports multiple languages\n",
    "- Saves extracted text to file\n",
    "- Option to keep or cleanup temporary image files\n",
    "\"\"\"\n",
    "\n",
    "#it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1723ff",
   "metadata": {},
   "source": [
    "## chromaDB embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b02a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully embedded 5 chunks from extracted_text.txt\n",
      "ğŸ’¾ Stored in collection: pdf_embeddings\n",
      "\n",
      "ğŸ“Š Collection: pdf_embeddings\n",
      "ğŸ“ˆ Total embeddings: 5\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”¹ ID: chunk_1\n",
      "ğŸ“„ Source: extracted_text.txt\n",
      "ğŸ“ Content Preview: 8/25/25,5.19 PM Calmly Writer Online 1 Introduction This privacy policy describes the personal data that Shopify processes (which may include collecting, organizing, structuring, storing, using, or di...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ ID: chunk_2\n",
      "ğŸ“„ Source: extracted_text.txt\n",
      "ğŸ“ Content Preview: as information about your browser and device privacy settings: 7 . Communications with Shopify: We receive information, including message and email content; when you communicate with Shopify (such as ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ ID: chunk_3\n",
      "ğŸ“„ Source: extracted_text.txt\n",
      "ğŸ“ Content Preview: to detect; investigate, and prevent malicious conduct; fraudulent activity or unsafe experiences, address security threats, protect public safety, and secure Shopify Services for you and our Merchants...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ ID: chunk_4\n",
      "ğŸ“„ Source: extracted_text.txt\n",
      "ğŸ“ Content Preview: including from law enforcement or government agencies; (2) enforce or investigate potential violations of our terms or policies; (3) detect; prevent; or investigate potential fraud, abuse, or safety a...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ ID: chunk_5\n",
      "ğŸ“„ Source: extracted_text.txt\n",
      "ğŸ“ Content Preview: include the following: 1. The length of time we and our Merchants have an ongoing relationship with you and provide Shopify services to you (for example, for as long as you have an account with us or ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ” Search Results for: 'Are third-party services covered by your privacy policy?'\n",
      "================================================================================\n",
      "\n",
      "1. ID: chunk_4\n",
      "   Distance: 0.7560\n",
      "   Content: including from law enforcement or government agencies; (2) enforce or investigate potential violations of our terms or policies; (3) detect; prevent; or investigate potential fraud, abuse, or safety and security concerns, including threats to the public; (4) meet our corporate and social responsibil...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. ID: chunk_3\n",
      "   Distance: 1.0852\n",
      "   Content: to detect; investigate, and prevent malicious conduct; fraudulent activity or unsafe experiences, address security threats, protect public safety, and secure Shopify Services for you and our Merchants: 7. Legal Reasons: To comply with applicable law or respond to valid legal process, including reque...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. ID: chunk_1\n",
      "   Distance: 1.0994\n",
      "   Content: 8/25/25,5.19 PM Calmly Writer Online 1 Introduction This privacy policy describes the personal data that Shopify processes (which may include collecting, organizing, structuring, storing, using, or disclosing) when you use or access Shopify Consumer Services, or when you interact with a merchant tha...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import os\n",
    "from chromadb.config import Settings\n",
    "\n",
    "class TextEmbedder:\n",
    "    def __init__(self, db_path=\"./chroma_db\"):\n",
    "        # Initialize ChromaDB client\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection_name = \"pdf_embeddings\"\n",
    "        \n",
    "        # Create or get collection\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=self.collection_name,\n",
    "            metadata={\"description\": \"PDF text embeddings\"}\n",
    "        )\n",
    "    \n",
    "    def chunk_text(self, text, chunk_size=500, overlap=50):\n",
    "        \"\"\"Split text into overlapping chunks.\"\"\"\n",
    "        chunks = []\n",
    "        words = text.split()\n",
    "        \n",
    "        for i in range(0, len(words), chunk_size - overlap):\n",
    "            chunk = \" \".join(words[i:i + chunk_size])\n",
    "            if chunk.strip():\n",
    "                chunks.append(chunk.strip())\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def embed_text_file(self, txt_file_path):\n",
    "        \"\"\"Read text file and embed it chunk by chunk.\"\"\"\n",
    "        if not os.path.exists(txt_file_path):\n",
    "            print(f\"âŒ File not found: {txt_file_path}\")\n",
    "            return\n",
    "        \n",
    "        \n",
    "        with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        \n",
    "        chunks = self.chunk_text(text)\n",
    "        \n",
    "        \n",
    "        documents = chunks\n",
    "        ids = [f\"chunk_{i+1}\" for i in range(len(chunks))]\n",
    "        metadatas = [{\"source\": txt_file_path, \"chunk_index\": i+1} for i in range(len(chunks))]\n",
    "        \n",
    "        \n",
    "        self.collection.add(\n",
    "            documents=documents,\n",
    "            ids=ids,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Successfully embedded {len(chunks)} chunks from {txt_file_path}\")\n",
    "        print(f\"ğŸ’¾ Stored in collection: {self.collection_name}\")\n",
    "        return len(chunks)\n",
    "    \n",
    "    def view_embeddings(self):\n",
    "        \"\"\"Display all embedded documents.\"\"\"\n",
    "        results = self.collection.get()\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Collection: {self.collection_name}\")\n",
    "        print(f\"ğŸ“ˆ Total embeddings: {len(results['ids'])}\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        for i, (doc_id, document, metadata) in enumerate(zip(\n",
    "            results['ids'], \n",
    "            results['documents'], \n",
    "            results['metadatas']\n",
    "        )):\n",
    "            print(f\"\\nğŸ”¹ ID: {doc_id}\")\n",
    "            print(f\"ğŸ“„ Source: {metadata['source']}\")\n",
    "            print(f\"ğŸ“ Content Preview: {document[:200]}...\")\n",
    "            print(\"-\" * 80)\n",
    "    \n",
    "    def search_similar(self, query, n_results=3):\n",
    "        \"\"\"Search for similar chunks.\"\"\"\n",
    "        results = self.collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ” Search Results for: '{query}'\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for i, (doc_id, document, metadata, distance) in enumerate(zip(\n",
    "            results['ids'][0], \n",
    "            results['documents'][0], \n",
    "            results['metadatas'][0],\n",
    "            results['distances'][0]\n",
    "        )):\n",
    "            print(f\"\\n{i+1}. ID: {doc_id}\")\n",
    "            print(f\"   Distance: {distance:.4f}\")\n",
    "            print(f\"   Content: {document[:300]}...\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize embedder\n",
    "    embedder = TextEmbedder()\n",
    "    \n",
    "    # Embed your text file (change this to your actual file)\n",
    "    txt_file = \"extracted_text.txt\"  # Change to your actual txt file name\n",
    "    \n",
    "    if os.path.exists(txt_file):\n",
    "        embedder.embed_text_file(txt_file)\n",
    "        \n",
    "        # View all embeddings\n",
    "        embedder.view_embeddings()\n",
    "        \n",
    "        # Example search (optional)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        search_query = input(\"Enter search query (or press Enter to skip): \").strip()\n",
    "        if search_query:\n",
    "            embedder.search_similar(search_query)\n",
    "    else:\n",
    "        print(f\"âŒ Text file '{txt_file}' not found!\")\n",
    "        print(\"Available txt files:\")\n",
    "        for file in os.listdir(\".\"):\n",
    "            if file.endswith(\".txt\"):\n",
    "                print(f\"  - {file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "#it worked embedding done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12bebc",
   "metadata": {},
   "source": [
    "## Chroma with structued.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d5409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully embedded 5 chunks from structured_output1.md\n",
      "ğŸ’¾ Stored in collection: pdf_embeddings\n",
      "\n",
      "ğŸ“Š Collection: pdf_embeddings\n",
      "ğŸ“ˆ Total embeddings: 5\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ”¹ ID: chunk_1\n",
      "ğŸ“„ Source: structured_output1.md\n",
      "ğŸ“ Content Preview: --- Page 1 --- # Calmly Writer Online # 8/25/25, 5.19 PM # Introduction # 1 # This privacy policy describes the personal data that Shopify processes (which may include # collecting, organizing, struct...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ ID: chunk_2\n",
      "ğŸ“„ Source: structured_output1.md\n",
      "ğŸ“ Content Preview: transaction # details and your payment information. Settings and Privacy Preferences: We receive information about your settings and 6. preferences on Shopify and our Merchants, as well as information...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ ID: chunk_3\n",
      "ğŸ“„ Source: structured_output1.md\n",
      "ğŸ“ Content Preview: information to respond to you when you contact uS. 6. Authentication, Integrity, Security, and Safety: To authenticate your account; provide payment and shopping experience, and to detect; investigate...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ ID: chunk_4\n",
      "ğŸ“„ Source: structured_output1.md\n",
      "ğŸ“ Content Preview: share Personal Data as needed to: (1) comply with applicable law or respond to, investigate, or participate in valid legal process and proceedings, including from law enforcement or government agencie...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ ID: chunk_5\n",
      "ğŸ“„ Source: structured_output1.md\n",
      "ğŸ“ Content Preview: security and fraud detection or prevention, or in connection* *or* *https:Ilwww calmlywriter comlonlinel* *5/7* --- Page 6 --- # Calmly Writer Online # 8/25/25, 5.19 PM # with backup or disaster recov...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ” Search Results for: 'Are third-party services covered by your privacy policy?'\n",
      "================================================================================\n",
      "\n",
      "1. ID: chunk_4\n",
      "   Distance: 0.8025\n",
      "   Content: share Personal Data as needed to: (1) comply with applicable law or respond to, investigate, or participate in valid legal process and proceedings, including from law enforcement or government agencies; (2) enforce or investigate potential violations of our terms or policies; (3) detect; prevent; or...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. ID: chunk_3\n",
      "   Distance: 1.1002\n",
      "   Content: information to respond to you when you contact uS. 6. Authentication, Integrity, Security, and Safety: To authenticate your account; provide payment and shopping experience, and to detect; investigate, and prevent a secure malicious conduct; fraudulent activity or unsafe experiences, address securit...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. ID: chunk_1\n",
      "   Distance: 1.1036\n",
      "   Content: --- Page 1 --- # Calmly Writer Online # 8/25/25, 5.19 PM # Introduction # 1 # This privacy policy describes the personal data that Shopify processes (which may include # collecting, organizing, structuring, storing, using, or disclosing) when you use or access # Shopify Consumer Services, or when yo...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import os\n",
    "from chromadb.config import Settings\n",
    "\n",
    "class TextEmbedder:\n",
    "    def __init__(self, db_path=\"./chroma_db_structured\"):\n",
    "        # Initialize ChromaDB client\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection_name = \"pdf_embeddings\"\n",
    "        \n",
    "        # Create or get collection\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=self.collection_name,\n",
    "            metadata={\"description\": \"PDF text embeddings\"}\n",
    "        )\n",
    "    \n",
    "    def chunk_text(self, text, chunk_size=500, overlap=50):\n",
    "        \"\"\"Split text into overlapping chunks.\"\"\"\n",
    "        chunks = []\n",
    "        words = text.split()\n",
    "        \n",
    "        for i in range(0, len(words), chunk_size - overlap):\n",
    "            chunk = \" \".join(words[i:i + chunk_size])\n",
    "            if chunk.strip():\n",
    "                chunks.append(chunk.strip())\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def embed_text(self, text: str, source: str = \"structured_output.md\"):\n",
    "        \"\"\"Embed the text provided directly (from structured_output.md).\"\"\"\n",
    "        # Split into chunks\n",
    "        chunks = self.chunk_text(text)\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        documents = chunks\n",
    "        ids = [f\"chunk_{i+1}\" for i in range(len(chunks))]\n",
    "        metadatas = [{\"source\": source, \"chunk_index\": i+1} for i in range(len(chunks))]\n",
    "        \n",
    "        # Add to ChromaDB\n",
    "        self.collection.add(\n",
    "            documents=documents,\n",
    "            ids=ids,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Successfully embedded {len(chunks)} chunks from {source}\")\n",
    "        print(f\"ğŸ’¾ Stored in collection: {self.collection_name}\")\n",
    "        return len(chunks)\n",
    "    \n",
    "    def view_embeddings(self):\n",
    "        \"\"\"Display all embedded documents.\"\"\"\n",
    "        results = self.collection.get()\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Collection: {self.collection_name}\")\n",
    "        print(f\"ğŸ“ˆ Total embeddings: {len(results['ids'])}\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        for i, (doc_id, document, metadata) in enumerate(zip(\n",
    "            results['ids'], \n",
    "            results['documents'], \n",
    "            results['metadatas']\n",
    "        )):\n",
    "            print(f\"\\nğŸ”¹ ID: {doc_id}\")\n",
    "            print(f\"ğŸ“„ Source: {metadata['source']}\")\n",
    "            print(f\"ğŸ“ Content Preview: {document[:200]}...\")\n",
    "            print(\"-\" * 80)\n",
    "    \n",
    "    def search_similar(self, query, n_results=3):\n",
    "        \"\"\"Search for similar chunks.\"\"\"\n",
    "        results = self.collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ” Search Results for: '{query}'\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for i, (doc_id, document, metadata, distance) in enumerate(zip(\n",
    "            results['ids'][0], \n",
    "            results['documents'][0], \n",
    "            results['metadatas'][0],\n",
    "            results['distances'][0]\n",
    "        )):\n",
    "            print(f\"\\n{i+1}. ID: {doc_id}\")\n",
    "            print(f\"   Distance: {distance:.4f}\")\n",
    "            print(f\"   Content: {document[:300]}...\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize embedder\n",
    "    embedder = TextEmbedder()\n",
    "    \n",
    "    # Read structured output from the markdown file\n",
    "    txt_file_path = \"structured_output1.md\"  # The OCR output file\n",
    "    \n",
    "    if os.path.exists(txt_file_path):\n",
    "        with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        # Embed the structured content from the file\n",
    "        embedder.embed_text(text, source=txt_file_path)\n",
    "        \n",
    "        # View all embeddings\n",
    "        embedder.view_embeddings()\n",
    "        \n",
    "        # Example search (optional)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        search_query = input(\"Enter search query (or press Enter to skip): \").strip()\n",
    "        if search_query:\n",
    "            embedder.search_similar(search_query)\n",
    "    else:\n",
    "        print(f\"âŒ Text file '{txt_file_path}' not found!\")\n",
    "        print(\"Available txt files:\")\n",
    "        for file in os.listdir(\".\"):\n",
    "            if file.endswith(\".md\"):  # Looking for markdown files\n",
    "                print(f\"  - {file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "#it worked embedding done structured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1638071d",
   "metadata": {},
   "source": [
    "## easyOCR versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import easyocr\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "import cv2\n",
    "\n",
    "class PDFOCRProcessor:\n",
    "    def __init__(self, languages=['en'], gpu=False):\n",
    "        \"\"\"\n",
    "        Initialize the PDF OCR processor\n",
    "        \n",
    "        Args:\n",
    "            languages (list): List of languages for OCR (e.g., ['en', 'es'])\n",
    "            gpu (bool): Whether to use GPU for OCR processing\n",
    "        \"\"\"\n",
    "        print(\"Initializing EasyOCR...\")\n",
    "        self.reader = easyocr.Reader(languages, gpu=gpu)\n",
    "        print(\"EasyOCR initialized successfully!\")\n",
    "    \n",
    "    def pdf_to_images(self, pdf_path: str, output_dir: str = None, dpi: int = 200) -> List[str]:\n",
    "        \"\"\"\n",
    "        Convert PDF pages to images\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            output_dir (str): Directory to save images (optional)\n",
    "            dpi (int): DPI for image conversion (higher = better quality)\n",
    "            \n",
    "        Returns:\n",
    "            List[str]: List of image file paths\n",
    "        \"\"\"\n",
    "        if not os.path.exists(pdf_path):\n",
    "            raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "        \n",
    "        # Create output directory if specified\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Open PDF\n",
    "        doc = fitz.open(pdf_path)\n",
    "        image_paths = []\n",
    "        \n",
    "        print(f\"Converting {len(doc)} pages to images...\")\n",
    "        \n",
    "        for page_num in range(len(doc)):\n",
    "            # Get page\n",
    "            page = doc[page_num]\n",
    "            \n",
    "            # Create transformation matrix for higher resolution\n",
    "            mat = fitz.Matrix(dpi/72, dpi/72)\n",
    "            \n",
    "            # Render page as image\n",
    "            pix = page.get_pixmap(matrix=mat)\n",
    "            \n",
    "            # Convert to PIL Image\n",
    "            img_data = pix.tobytes(\"png\")\n",
    "            img = Image.open(io.BytesIO(img_data)) if 'io' in globals() else None\n",
    "            \n",
    "            # Alternative method using pix.pil_tobytes()\n",
    "            if img is None:\n",
    "                img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            # Save image\n",
    "            if output_dir:\n",
    "                image_path = os.path.join(output_dir, f\"page_{page_num + 1}.png\")\n",
    "                img.save(image_path, \"PNG\")\n",
    "                image_paths.append(image_path)\n",
    "            else:\n",
    "                # Save to temporary location\n",
    "                image_path = f\"temp_page_{page_num + 1}.png\"\n",
    "                img.save(image_path, \"PNG\")\n",
    "                image_paths.append(image_path)\n",
    "            \n",
    "            print(f\"Page {page_num + 1} converted to image\")\n",
    "        \n",
    "        doc.close()\n",
    "        return image_paths\n",
    "    \n",
    "    def enhance_image_for_ocr(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Enhance image quality for better OCR results\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Enhanced image array\n",
    "        \"\"\"\n",
    "        # Read image\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply denoising\n",
    "        denoised = cv2.fastNlMeansDenoising(gray)\n",
    "        \n",
    "        # Apply adaptive thresholding for better contrast\n",
    "        thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                       cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        return thresh\n",
    "    \n",
    "    def extract_text_from_image(self, image_path: str, enhance: bool = True) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Extract text from image using EasyOCR\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file\n",
    "            enhance (bool): Whether to enhance image before OCR\n",
    "            \n",
    "        Returns:\n",
    "            List[Tuple[str, float]]: List of (text, confidence) tuples\n",
    "        \"\"\"\n",
    "        if enhance:\n",
    "            # Use enhanced image\n",
    "            img = self.enhance_image_for_ocr(image_path)\n",
    "            results = self.reader.readtext(img)\n",
    "        else:\n",
    "            # Use original image\n",
    "            results = self.reader.readtext(image_path)\n",
    "        \n",
    "        # Extract text and confidence scores\n",
    "        text_results = []\n",
    "        for result in results:\n",
    "            text = result[1]\n",
    "            confidence = result[2]\n",
    "            text_results.append((text, confidence))\n",
    "        \n",
    "        return text_results\n",
    "    \n",
    "    def process_pdf(self, pdf_path: str, output_dir: str = None, \n",
    "                   enhance_images: bool = True, confidence_threshold: float = 0.5,\n",
    "                   cleanup_temp: bool = True) -> dict:\n",
    "        \"\"\"\n",
    "        Complete pipeline: PDF -> Images -> OCR\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            output_dir (str): Directory to save images (optional)\n",
    "            enhance_images (bool): Whether to enhance images for OCR\n",
    "            confidence_threshold (float): Minimum confidence for text extraction\n",
    "            cleanup_temp (bool): Whether to cleanup temporary image files\n",
    "            \n",
    "        Returns:\n",
    "            dict: Results containing text from each page\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'pdf_path': pdf_path,\n",
    "            'pages': [],\n",
    "            'total_pages': 0,\n",
    "            'extracted_text': ''\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Convert PDF to images\n",
    "            print(\"Step 1: Converting PDF to images...\")\n",
    "            image_paths = self.pdf_to_images(pdf_path, output_dir)\n",
    "            results['total_pages'] = len(image_paths)\n",
    "            \n",
    "            # Step 2: Extract text from each image\n",
    "            print(\"Step 2: Extracting text from images...\")\n",
    "            all_text = []\n",
    "            \n",
    "            for i, image_path in enumerate(image_paths):\n",
    "                print(f\"Processing page {i + 1}/{len(image_paths)}...\")\n",
    "                \n",
    "                # Extract text\n",
    "                text_results = self.extract_text_from_image(image_path, enhance_images)\n",
    "                \n",
    "                # Filter by confidence threshold\n",
    "                filtered_text = [text for text, conf in text_results if conf >= confidence_threshold]\n",
    "                \n",
    "                page_text = ' '.join(filtered_text)\n",
    "                all_text.append(page_text)\n",
    "                \n",
    "                page_info = {\n",
    "                    'page_number': i + 1,\n",
    "                    'image_path': image_path,\n",
    "                    'text': page_text,\n",
    "                    'raw_results': text_results\n",
    "                }\n",
    "                results['pages'].append(page_info)\n",
    "            \n",
    "            # Combine all text\n",
    "            results['extracted_text'] = '\\n\\n--- Page Break ---\\n\\n'.join(all_text)\n",
    "            \n",
    "            # Cleanup temporary files if requested\n",
    "            if cleanup_temp and not output_dir:\n",
    "                for image_path in image_paths:\n",
    "                    if os.path.exists(image_path) and image_path.startswith('temp_'):\n",
    "                        os.remove(image_path)\n",
    "                        print(f\"Cleaned up temporary file: {image_path}\")\n",
    "            \n",
    "            print(\"Processing completed successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during processing: {str(e)}\")\n",
    "            results['error'] = str(e)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the PDFOCRProcessor\n",
    "    \"\"\"\n",
    "    # Initialize processor\n",
    "    # For multiple languages, use: languages=['en', 'es', 'fr']\n",
    "    processor = PDFOCRProcessor(languages=['en'], gpu=False)\n",
    "    \n",
    "    # Path to your PDF file\n",
    "    pdf_path = \"sample_document.pdf\"  # Change this to your PDF path\n",
    "    \n",
    "    # Optional: specify output directory for images\n",
    "    output_dir = \"extracted_images\"  # Set to None to use temporary files\n",
    "    \n",
    "    # Process the PDF\n",
    "    results = processor.process_pdf(\n",
    "        pdf_path=pdf_path,\n",
    "        output_dir=output_dir,\n",
    "        enhance_images=True,\n",
    "        confidence_threshold=0.5,\n",
    "        cleanup_temp=True\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    if 'error' not in results:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"EXTRACTION RESULTS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Total pages processed: {results['total_pages']}\")\n",
    "        print(f\"\\nExtracted Text:\\n{'-'*30}\")\n",
    "        print(results['extracted_text'])\n",
    "        \n",
    "        # Save extracted text to file\n",
    "        with open('extracted_text.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(results['extracted_text'])\n",
    "        print(f\"\\nExtracted text saved to: extracted_text.txt\")\n",
    "        \n",
    "        # Print page-wise details\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"PAGE-WISE DETAILS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        for page in results['pages']:\n",
    "            print(f\"\\nPage {page['page_number']}:\")\n",
    "            print(f\"Text: {page['text'][:200]}...\" if len(page['text']) > 200 else f\"Text: {page['text']}\")\n",
    "    else:\n",
    "        print(f\"Error occurred: {results['error']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Import required libraries check\n",
    "    try:\n",
    "        import io\n",
    "    except ImportError:\n",
    "        import io\n",
    "    \n",
    "    main()\n",
    "\n",
    "\"\"\"\n",
    "Installation requirements:\n",
    "pip install easyocr PyMuPDF pillow opencv-python numpy\n",
    "\n",
    "Usage:\n",
    "1. Install the required packages\n",
    "2. Replace 'sample_document.pdf' with your PDF path\n",
    "3. Run the script\n",
    "4. The extracted text will be saved to 'extracted_text.txt'\n",
    "\n",
    "Features:\n",
    "- Converts PDF pages to high-resolution images\n",
    "- Enhances images for better OCR accuracy\n",
    "- Extracts text with confidence scores\n",
    "- Filters results by confidence threshold\n",
    "- Supports multiple languages\n",
    "- Saves extracted text to file\n",
    "- Option to keep or cleanup temporary image files\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43447c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing EasyOCR...\n",
      "EasyOCR initialized successfully!\n",
      "============================================================\n",
      "PROCESSING WITH DIFFERENT FORMATS\n",
      "============================================================\n",
      "\n",
      "1. MARKDOWN FORMAT (Best for tables and structure)\n",
      "Step 1: Converting PDF to images...\n",
      "Converting 7 pages to images...\n",
      "Page 1 converted (DPI: 300)\n",
      "Page 2 converted (DPI: 300)\n",
      "Page 3 converted (DPI: 300)\n",
      "Page 4 converted (DPI: 300)\n",
      "Page 5 converted (DPI: 300)\n",
      "Page 6 converted (DPI: 300)\n",
      "Page 7 converted (DPI: 300)\n",
      "Step 2: Processing page 1/7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Busra\\Melikoz\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Processing page 2/7...\n",
      "Step 2: Processing page 3/7...\n",
      "Step 2: Processing page 4/7...\n",
      "Step 2: Processing page 5/7...\n",
      "Step 2: Processing page 6/7...\n",
      "Step 2: Processing page 7/7...\n",
      "Step 3: Creating embedding-ready chunks...\n",
      "Processing completed successfully!\n",
      "Structured Content Preview:\n",
      "--- Page 1 ---\n",
      "# Calmly Writer Online\n",
      "\n",
      "# 8/25/25, 5.19 PM\n",
      "\n",
      "# Introduction\n",
      "\n",
      "# 1\n",
      "\n",
      "# This privacy policy describes the personal data that Shopify processes (which may include\n",
      "\n",
      "# collecting, organizing, structuring, storing, using, or disclosing) when you use or access\n",
      "\n",
      "# Shopify Consumer Services, or when you interact with a merchant that is powered by\n",
      "\n",
      "# Shopify's platform (\"Shopify Merchants\" or \"Merchants\") . If any provisions in this policy\n",
      "\n",
      "conflict with provisions of any other Shopify privacy policy, the provisions in this policy will\n",
      "\n",
      "apply:\n",
      "\n",
      "2. What Personal Data We Receive\n",
      "\n",
      "Personal Data is any information from or about an identified or identifiable person, but does\n",
      "\n",
      "not include aggregated or anonymized information: We receive the following types of\n",
      "\n",
      "Personal Data when you interact with Shopify, Shopify Merchants, and/or use the Shopify\n",
      "\n",
      "Consumer Services:\n",
      "\n",
      "1. Profile and Contact Information: We receive contact or other account profile\n",
      "\n",
      "information when you sign up for or interac...\n",
      "\n",
      "Files saved:\n",
      "- Structured content: structured_output1.md\n",
      "- Embedding chunks: embedding_chunks.json\n",
      "- Total chunks for embeddings: 31\n",
      "\n",
      "2. JSON FORMAT (Best for programmatic processing)\n",
      "Step 1: Converting PDF to images...\n",
      "Converting 7 pages to images...\n",
      "Page 1 converted (DPI: 300)\n",
      "Page 2 converted (DPI: 300)\n",
      "Page 3 converted (DPI: 300)\n",
      "Page 4 converted (DPI: 300)\n",
      "Page 5 converted (DPI: 300)\n",
      "Page 6 converted (DPI: 300)\n",
      "Page 7 converted (DPI: 300)\n",
      "Step 2: Processing page 1/7...\n",
      "Error: Object of type int32 is not JSON serializable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nRECOMMENDED APPROACHES FOR EMBEDDINGS:\\n\\n1. **For Financial Documents (like credit reports):**\\n   - Use Markdown format to preserve table structure\\n   - Create chunks that respect logical boundaries (complete sections)\\n   - Include metadata about content type (header, table, text)\\n\\n2. **Best Practices:**\\n   - DPI 300+ for better text detection\\n   - Structure-aware chunking (don't split tables)\\n   - Preserve context with section headers\\n   - Include bounding box information for spatial understanding\\n\\n3. **For Better Embeddings:**\\n   - Keep related information together (account details + payment history)\\n   - Use semantic boundaries rather than fixed character limits\\n   - Include document structure markers\\n   - Preserve table relationships\\n\\nInstallation:\\npip install easyocr PyMuPDF pillow opencv-python pandas numpy\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "import easyocr\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import os\n",
    "import io\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TextBlock:\n",
    "    text: str\n",
    "    bbox: Tuple[int, int, int, int]  # x1, y1, x2, y2\n",
    "    confidence: float\n",
    "    block_type: str = \"text\"  # text, table, header, footer\n",
    "\n",
    "class AdvancedPDFOCR:\n",
    "    def __init__(self, languages=['en'], gpu=False):\n",
    "        \"\"\"\n",
    "        Advanced PDF OCR processor with structure preservation\n",
    "        \"\"\"\n",
    "        print(\"Initializing EasyOCR...\")\n",
    "        self.reader = easyocr.Reader(languages, gpu=gpu)\n",
    "        print(\"EasyOCR initialized successfully!\")\n",
    "    \n",
    "    def pdf_to_images(self, pdf_path: str, output_dir: str = None, dpi: int = 300) -> List[str]:\n",
    "        \"\"\"Convert PDF to high-quality images\"\"\"\n",
    "        if not os.path.exists(pdf_path):\n",
    "            raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "        \n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        doc = fitz.open(pdf_path)\n",
    "        image_paths = []\n",
    "        \n",
    "        print(f\"Converting {len(doc)} pages to images...\")\n",
    "        \n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc[page_num]\n",
    "            mat = fitz.Matrix(dpi/72, dpi/72)\n",
    "            pix = page.get_pixmap(matrix=mat)\n",
    "            \n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            if output_dir:\n",
    "                image_path = os.path.join(output_dir, f\"page_{page_num + 1}.png\")\n",
    "            else:\n",
    "                image_path = f\"temp_page_{page_num + 1}.png\"\n",
    "            \n",
    "            img.save(image_path, \"PNG\", dpi=(dpi, dpi))\n",
    "            image_paths.append(image_path)\n",
    "            print(f\"Page {page_num + 1} converted (DPI: {dpi})\")\n",
    "        \n",
    "        doc.close()\n",
    "        return image_paths\n",
    "    \n",
    "    def detect_text_blocks(self, image_path: str) -> List[TextBlock]:\n",
    "        \"\"\"\n",
    "        Detect text blocks with bounding boxes for structure analysis\n",
    "        \"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        results = self.reader.readtext(img)\n",
    "        \n",
    "        text_blocks = []\n",
    "        for result in results:\n",
    "            bbox_points = result[0]  # 4 corner points\n",
    "            text = result[1]\n",
    "            confidence = result[2]\n",
    "            \n",
    "            # Convert bbox points to rectangle coordinates\n",
    "            x_coords = [point[0] for point in bbox_points]\n",
    "            y_coords = [point[1] for point in bbox_points]\n",
    "            x1, y1, x2, y2 = min(x_coords), min(y_coords), max(x_coords), max(y_coords)\n",
    "            \n",
    "            block = TextBlock(text, (x1, y1, x2, y2), confidence)\n",
    "            text_blocks.append(block)\n",
    "        \n",
    "        return text_blocks\n",
    "    \n",
    "    def analyze_layout(self, text_blocks: List[TextBlock], img_shape: Tuple[int, int]) -> List[TextBlock]:\n",
    "        \"\"\"\n",
    "        Analyze layout to identify headers, tables, and text sections\n",
    "        \"\"\"\n",
    "        height, width = img_shape[:2]\n",
    "        \n",
    "        # Sort blocks by vertical position\n",
    "        sorted_blocks = sorted(text_blocks, key=lambda b: b.bbox[1])\n",
    "        \n",
    "        for i, block in enumerate(sorted_blocks):\n",
    "            x1, y1, x2, y2 = block.bbox\n",
    "            \n",
    "            # Identify potential headers (top 20% of page, larger text)\n",
    "            if y1 < height * 0.2:\n",
    "                block.block_type = \"header\"\n",
    "            \n",
    "            # Identify potential footers (bottom 10% of page)\n",
    "            elif y1 > height * 0.9:\n",
    "                block.block_type = \"footer\"\n",
    "            \n",
    "            # Detect potential table content (aligned text in columns)\n",
    "            elif self._is_table_like(block, sorted_blocks, i):\n",
    "                block.block_type = \"table\"\n",
    "            \n",
    "            else:\n",
    "                block.block_type = \"text\"\n",
    "        \n",
    "        return sorted_blocks\n",
    "    \n",
    "    def _is_table_like(self, block: TextBlock, all_blocks: List[TextBlock], index: int) -> bool:\n",
    "        \"\"\"\n",
    "        Simple heuristic to detect table-like content\n",
    "        \"\"\"\n",
    "        x1, y1, x2, y2 = block.bbox\n",
    "        \n",
    "        # Look for blocks with similar y-coordinates (same row)\n",
    "        same_row_blocks = []\n",
    "        for other_block in all_blocks:\n",
    "            ox1, oy1, ox2, oy2 = other_block.bbox\n",
    "            # If vertically aligned (similar y-coordinates)\n",
    "            if abs(y1 - oy1) < 10 and abs(y2 - oy2) < 10 and other_block != block:\n",
    "                same_row_blocks.append(other_block)\n",
    "        \n",
    "        # If we have multiple blocks in the same row, it might be a table\n",
    "        return len(same_row_blocks) >= 2\n",
    "    \n",
    "    def reconstruct_structure(self, text_blocks: List[TextBlock], preserve_format: str = \"markdown\") -> str:\n",
    "        \"\"\"\n",
    "        Reconstruct text with preserved structure\n",
    "        \"\"\"\n",
    "        if preserve_format == \"markdown\":\n",
    "            return self._to_markdown(text_blocks)\n",
    "        elif preserve_format == \"json\":\n",
    "            return self._to_json(text_blocks)\n",
    "        elif preserve_format == \"xml\":\n",
    "            return self._to_xml(text_blocks)\n",
    "        else:\n",
    "            return self._to_structured_text(text_blocks)\n",
    "    \n",
    "    def _to_markdown(self, text_blocks: List[TextBlock]) -> str:\n",
    "        \"\"\"Convert to Markdown with preserved structure\"\"\"\n",
    "        markdown_content = []\n",
    "        current_table_rows = []\n",
    "        in_table = False\n",
    "        \n",
    "        for block in text_blocks:\n",
    "            if block.block_type == \"header\":\n",
    "                if in_table and current_table_rows:\n",
    "                    markdown_content.extend(self._format_table_markdown(current_table_rows))\n",
    "                    current_table_rows = []\n",
    "                    in_table = False\n",
    "                markdown_content.append(f\"# {block.text}\")\n",
    "            \n",
    "            elif block.block_type == \"table\":\n",
    "                if not in_table:\n",
    "                    in_table = True\n",
    "                current_table_rows.append(block)\n",
    "            \n",
    "            elif block.block_type == \"footer\":\n",
    "                if in_table and current_table_rows:\n",
    "                    markdown_content.extend(self._format_table_markdown(current_table_rows))\n",
    "                    current_table_rows = []\n",
    "                    in_table = False\n",
    "                markdown_content.append(f\"*{block.text}*\")\n",
    "            \n",
    "            else:  # regular text\n",
    "                if in_table and current_table_rows:\n",
    "                    markdown_content.extend(self._format_table_markdown(current_table_rows))\n",
    "                    current_table_rows = []\n",
    "                    in_table = False\n",
    "                markdown_content.append(block.text)\n",
    "        \n",
    "        # Handle remaining table rows\n",
    "        if in_table and current_table_rows:\n",
    "            markdown_content.extend(self._format_table_markdown(current_table_rows))\n",
    "        \n",
    "        return \"\\n\\n\".join(markdown_content)\n",
    "    \n",
    "    def _format_table_markdown(self, table_blocks: List[TextBlock]) -> List[str]:\n",
    "        \"\"\"Format table blocks as Markdown table\"\"\"\n",
    "        if not table_blocks:\n",
    "            return []\n",
    "        \n",
    "        # Group blocks by rows based on y-coordinates\n",
    "        rows = []\n",
    "        current_row = []\n",
    "        current_y = table_blocks[0].bbox[1]\n",
    "        \n",
    "        for block in sorted(table_blocks, key=lambda b: (b.bbox[1], b.bbox[0])):\n",
    "            if abs(block.bbox[1] - current_y) > 20:  # New row\n",
    "                if current_row:\n",
    "                    rows.append(current_row)\n",
    "                current_row = [block]\n",
    "                current_y = block.bbox[1]\n",
    "            else:\n",
    "                current_row.append(block)\n",
    "        \n",
    "        if current_row:\n",
    "            rows.append(current_row)\n",
    "        \n",
    "        if not rows:\n",
    "            return []\n",
    "        \n",
    "        # Convert to markdown table\n",
    "        markdown_rows = []\n",
    "        for i, row in enumerate(rows):\n",
    "            row_text = \" | \".join([block.text for block in row])\n",
    "            markdown_rows.append(f\"| {row_text} |\")\n",
    "            \n",
    "            # Add header separator after first row\n",
    "            if i == 0:\n",
    "                separator = \" | \".join([\"---\"] * len(row))\n",
    "                markdown_rows.append(f\"| {separator} |\")\n",
    "        \n",
    "        return markdown_rows\n",
    "    \n",
    "    def _to_json(self, text_blocks: List[TextBlock]) -> str:\n",
    "        \"\"\"Convert to JSON structure\"\"\"\n",
    "        json_data = {\n",
    "            \"document_structure\": [],\n",
    "            \"metadata\": {\n",
    "                \"total_blocks\": len(text_blocks),\n",
    "                \"block_types\": {}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for block in text_blocks:\n",
    "            block_data = {\n",
    "                \"text\": block.text,\n",
    "                \"type\": block.block_type,\n",
    "                \"bbox\": block.bbox,\n",
    "                \"confidence\": block.confidence\n",
    "            }\n",
    "            json_data[\"document_structure\"].append(block_data)\n",
    "            \n",
    "            # Update metadata\n",
    "            if block.block_type in json_data[\"metadata\"][\"block_types\"]:\n",
    "                json_data[\"metadata\"][\"block_types\"][block.block_type] += 1\n",
    "            else:\n",
    "                json_data[\"metadata\"][\"block_types\"][block.block_type] = 1\n",
    "        \n",
    "        return json.dumps(json_data, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    def _to_xml(self, text_blocks: List[TextBlock]) -> str:\n",
    "        \"\"\"Convert to XML structure\"\"\"\n",
    "        xml_content = ['<?xml version=\"1.0\" encoding=\"UTF-8\"?>', '<document>']\n",
    "        \n",
    "        for block in text_blocks:\n",
    "            x1, y1, x2, y2 = block.bbox\n",
    "            xml_content.append(\n",
    "                f'  <{block.block_type} '\n",
    "                f'bbox=\"{x1},{y1},{x2},{y2}\" '\n",
    "                f'confidence=\"{block.confidence:.2f}\">'\n",
    "            )\n",
    "            xml_content.append(f'    {block.text}')\n",
    "            xml_content.append(f'  </{block.block_type}>')\n",
    "        \n",
    "        xml_content.append('</document>')\n",
    "        return '\\n'.join(xml_content)\n",
    "    \n",
    "    def _to_structured_text(self, text_blocks: List[TextBlock]) -> str:\n",
    "        \"\"\"Convert to structured plain text\"\"\"\n",
    "        structured_content = []\n",
    "        \n",
    "        for block in text_blocks:\n",
    "            if block.block_type == \"header\":\n",
    "                structured_content.append(f\"\\n[HEADER] {block.text}\")\n",
    "            elif block.block_type == \"table\":\n",
    "                structured_content.append(f\"[TABLE_CELL] {block.text}\")\n",
    "            elif block.block_type == \"footer\":\n",
    "                structured_content.append(f\"[FOOTER] {block.text}\")\n",
    "            else:\n",
    "                structured_content.append(block.text)\n",
    "        \n",
    "        return \"\\n\".join(structured_content)\n",
    "    \n",
    "    def create_embeddings_ready_chunks(self, structured_text: str, chunk_size: int = 512) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Create embedding-ready chunks with context preservation\n",
    "        \"\"\"\n",
    "        chunks = []\n",
    "        \n",
    "        # Split by major sections while preserving structure\n",
    "        sections = structured_text.split('\\n\\n')\n",
    "        current_chunk = \"\"\n",
    "        chunk_metadata = {\"type\": \"mixed\", \"contains_table\": False, \"contains_header\": False}\n",
    "        \n",
    "        for section in sections:\n",
    "            # Check if adding this section would exceed chunk size\n",
    "            if len(current_chunk + section) > chunk_size and current_chunk:\n",
    "                # Save current chunk\n",
    "                chunks.append({\n",
    "                    \"text\": current_chunk.strip(),\n",
    "                    \"metadata\": chunk_metadata.copy(),\n",
    "                    \"length\": len(current_chunk)\n",
    "                })\n",
    "                current_chunk = section\n",
    "                chunk_metadata = {\"type\": \"mixed\", \"contains_table\": False, \"contains_header\": False}\n",
    "            else:\n",
    "                current_chunk += \"\\n\\n\" + section if current_chunk else section\n",
    "            \n",
    "            # Update metadata based on content\n",
    "            if section.startswith(\"#\") or \"[HEADER]\" in section:\n",
    "                chunk_metadata[\"contains_header\"] = True\n",
    "            if \"|\" in section or \"[TABLE_CELL]\" in section:\n",
    "                chunk_metadata[\"contains_table\"] = True\n",
    "        \n",
    "        # Add final chunk\n",
    "        if current_chunk:\n",
    "            chunks.append({\n",
    "                \"text\": current_chunk.strip(),\n",
    "                \"metadata\": chunk_metadata,\n",
    "                \"length\": len(current_chunk)\n",
    "            })\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def process_pdf_advanced(self, pdf_path: str, output_format: str = \"markdown\", \n",
    "                           chunk_for_embeddings: bool = True, confidence_threshold: float = 0.5) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Advanced PDF processing with structure preservation\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            \"pdf_path\": pdf_path,\n",
    "            \"pages\": [],\n",
    "            \"structured_content\": \"\",\n",
    "            \"embedding_chunks\": [],\n",
    "            \"metadata\": {}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Convert PDF to images\n",
    "            print(\"Step 1: Converting PDF to images...\")\n",
    "            image_paths = self.pdf_to_images(pdf_path)\n",
    "            \n",
    "            all_structured_content = []\n",
    "            \n",
    "            # Process each page\n",
    "            for i, image_path in enumerate(image_paths):\n",
    "                print(f\"Step 2: Processing page {i + 1}/{len(image_paths)}...\")\n",
    "                \n",
    "                # Detect text blocks with positions\n",
    "                text_blocks = self.detect_text_blocks(image_path)\n",
    "                \n",
    "                # Filter by confidence\n",
    "                filtered_blocks = [b for b in text_blocks if b.confidence >= confidence_threshold]\n",
    "                \n",
    "                # Analyze layout\n",
    "                img = cv2.imread(image_path)\n",
    "                structured_blocks = self.analyze_layout(filtered_blocks, img.shape)\n",
    "                \n",
    "                # Reconstruct with structure\n",
    "                page_content = self.reconstruct_structure(structured_blocks, output_format)\n",
    "                all_structured_content.append(f\"--- Page {i + 1} ---\\n{page_content}\")\n",
    "                \n",
    "                # Store page info\n",
    "                results[\"pages\"].append({\n",
    "                    \"page_number\": i + 1,\n",
    "                    \"blocks\": len(structured_blocks),\n",
    "                    \"content\": page_content,\n",
    "                    \"block_types\": {block.block_type: 1 for block in structured_blocks}\n",
    "                })\n",
    "            \n",
    "            # Combine all content\n",
    "            results[\"structured_content\"] = \"\\n\\n\".join(all_structured_content)\n",
    "            \n",
    "            # Create embedding chunks if requested\n",
    "            if chunk_for_embeddings:\n",
    "                print(\"Step 3: Creating embedding-ready chunks...\")\n",
    "                results[\"embedding_chunks\"] = self.create_embeddings_ready_chunks(\n",
    "                    results[\"structured_content\"]\n",
    "                )\n",
    "            \n",
    "            # Add metadata\n",
    "            results[\"metadata\"] = {\n",
    "                \"total_pages\": len(image_paths),\n",
    "                \"output_format\": output_format,\n",
    "                \"total_chunks\": len(results[\"embedding_chunks\"]) if chunk_for_embeddings else 0,\n",
    "                \"processing_complete\": True\n",
    "            }\n",
    "            \n",
    "            # Cleanup temp files\n",
    "            for image_path in image_paths:\n",
    "                if image_path.startswith('temp_'):\n",
    "                    os.remove(image_path)\n",
    "            print(\"Processing completed successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            results[\"error\"] = str(e)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Usage examples\n",
    "def demo_usage():\n",
    "    \"\"\"\n",
    "    Demonstration of different output formats and embedding preparation\n",
    "    \"\"\"\n",
    "    processor = AdvancedPDFOCR(languages=['en'], gpu=False)\n",
    "    pdf_path = \"./New folder/privacy_policy.pdf\"  # Your PDF path\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"PROCESSING WITH DIFFERENT FORMATS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Process with Markdown format (best for tables)\n",
    "    print(\"\\n1. MARKDOWN FORMAT (Best for tables and structure)\")\n",
    "    results_md = processor.process_pdf_advanced(\n",
    "        pdf_path, \n",
    "        output_format=\"markdown\", \n",
    "        chunk_for_embeddings=True\n",
    "    )\n",
    "    \n",
    "    if \"error\" not in results_md:\n",
    "        print(\"Structured Content Preview:\")\n",
    "        print(results_md[\"structured_content\"][:1000] + \"...\")\n",
    "        \n",
    "        # Save outputs\n",
    "        with open(\"structured_output1.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(results_md[\"structured_content\"])\n",
    "        \n",
    "        # Save embedding chunks\n",
    "        with open(\"embedding_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results_md[\"embedding_chunks\"], f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nFiles saved:\")\n",
    "        print(f\"- Structured content: structured_output1.md\")\n",
    "        print(f\"- Embedding chunks: embedding_chunks.json\")\n",
    "        print(f\"- Total chunks for embeddings: {len(results_md['embedding_chunks'])}\")\n",
    "    \n",
    "    # Process with JSON format (best for programmatic access)\n",
    "    print(\"\\n2. JSON FORMAT (Best for programmatic processing)\")\n",
    "    results_json = processor.process_pdf_advanced(\n",
    "        pdf_path, \n",
    "        output_format=\"json\", \n",
    "        chunk_for_embeddings=False\n",
    "    )\n",
    "    \n",
    "    if \"error\" not in results_json:\n",
    "        with open(\"structured_output1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(results_json[\"structured_content\"])\n",
    "        print(\"JSON structure saved to: structured_output1.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_usage()\n",
    "\n",
    "\"\"\"\n",
    "RECOMMENDED APPROACHES FOR EMBEDDINGS:\n",
    "\n",
    "1. **For Financial Documents (like credit reports):**\n",
    "   - Use Markdown format to preserve table structure\n",
    "   - Create chunks that respect logical boundaries (complete sections)\n",
    "   - Include metadata about content type (header, table, text)\n",
    "\n",
    "2. **Best Practices:**\n",
    "   - DPI 300+ for better text detection\n",
    "   - Structure-aware chunking (don't split tables)\n",
    "   - Preserve context with section headers\n",
    "   - Include bounding box information for spatial understanding\n",
    "\n",
    "3. **For Better Embeddings:**\n",
    "   - Keep related information together (account details + payment history)\n",
    "   - Use semantic boundaries rather than fixed character limits\n",
    "   - Include document structure markers\n",
    "   - Preserve table relationships\n",
    "\n",
    "Installation:\n",
    "pip install easyocr PyMuPDF pillow opencv-python pandas numpy\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#structure_output.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a72174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HAVE TO GPT THIS FOR ACHEIVE GOOD OCR RESULT\n",
    "\n",
    "\n",
    "# Using CPU. Note: This module is much faster with a GPU.\n",
    "# Initializing EasyOCR...\n",
    "# EasyOCR initialized successfully!\n",
    "# ============================================================\n",
    "# PROCESSING WITH DIFFERENT FORMATS\n",
    "# ============================================================\n",
    "\n",
    "# 1. MARKDOWN FORMAT (Best for tables and structure)\n",
    "# Step 1: Converting PDF to images...\n",
    "# Converting 7 pages to images...\n",
    "# Page 1 converted (DPI: 300)\n",
    "# Page 2 converted (DPI: 300)\n",
    "# Page 3 converted (DPI: 300)\n",
    "# Page 4 converted (DPI: 300)\n",
    "# Page 5 converted (DPI: 300)\n",
    "# Page 6 converted (DPI: 300)\n",
    "# Page 7 converted (DPI: 300)\n",
    "# Step 2: Processing page 1/7...\n",
    "# c:\\Users\\Busra\\Melikoz\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
    "#   warnings.warn(warn_msg)\n",
    "# Step 2: Processing page 2/7...\n",
    "# Step 2: Processing page 3/7...\n",
    "# Step 2: Processing page 4/7...\n",
    "# Step 2: Processing page 5/7...\n",
    "# Step 2: Processing page 6/7...\n",
    "# Step 2: Processing page 7/7...\n",
    "# Step 3: Creating embedding-ready chunks...\n",
    "# Processing completed successfully!\n",
    "# Structured Content Preview:\n",
    "# --- Page 1 ---\n",
    "# # Calmly Writer Online\n",
    "\n",
    "# # 8/25/25, 5.19 PM\n",
    "\n",
    "# # Introduction\n",
    "\n",
    "# # 1\n",
    "\n",
    "# # This privacy policy describes the personal data that Shopify processes (which may include\n",
    "\n",
    "# # collecting, organizing, structuring, storing, using, or disclosing) when you use or access\n",
    "\n",
    "# # Shopify Consumer Services, or when you interact with a merchant that is powered by\n",
    "\n",
    "# # Shopify's platform (\"Shopify Merchants\" or \"Merchants\") . If any provisions in this policy\n",
    "# ...\n",
    "# Page 6 converted (DPI: 300)\n",
    "# Page 7 converted (DPI: 300)\n",
    "# Step 2: Processing page 1/7...\n",
    "# Error: Object of type int32 is not JSON serializable\n",
    "# Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n",
    "# \"\\nRECOMMENDED APPROACHES FOR EMBEDDINGS:\\n\\n1. **For Financial Documents (like credit reports):**\\n   - Use Markdown format to preserve table structure\\n   - Create chunks that respect logical boundaries (complete sections)\\n   - Include metadata about content type (header, table, text)\\n\\n2. **Best Practices:**\\n   - DPI 300+ for better text detection\\n   - Structure-aware chunking (don't split tables)\\n   - Preserve context with section headers\\n   - Include bounding box information for spatial understanding\\n\\n3. **For Better Embeddings:**\\n   - Keep related information together (account details + payment history)\\n   - Use semantic boundaries rather than fixed character limits\\n   - Include document structure markers\\n   - Preserve table relationships\\n\\nInstallation:\\npip install easyocr PyMuPDF pillow opencv-python pandas numpy\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3PDF to image\n",
    "import fitz  # PyMuPDF for PDF -> images\n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "class PDFImageExtractor:\n",
    "    def init(self, pdf_path, output_folder=\"pdf_images\"):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "    def pdf_to_images(self):\n",
    "        \"\"\"Convert each page of PDF to JPG image and return paths.\"\"\"\n",
    "        doc = fitz.open(self.pdf_path)\n",
    "        if not os.path.exists(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "\n",
    "        image_paths = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap(dpi=200)  # higher DPI for better quality\n",
    "            image_path = os.path.join(self.outputfolder, f\"page{page_num + 1}.jpg\")\n",
    "            pix.save(image_path)\n",
    "            image_paths.append(image_path)\n",
    "            print(f\"âœ… Page {page_num + 1} saved as {image_path}\")\n",
    "        doc.close()\n",
    "        return image_paths\n",
    "\n",
    "    def cleanup_images(self):\n",
    "        \"\"\"Delete all images from the output folder after extraction.\"\"\"\n",
    "        if os.path.exists(self.output_folder):\n",
    "            shutil.rmtree(self.output_folder)\n",
    "            print(f\"ğŸ—‘ï¸ Deleted temporary folder: {self.output_folder}\")\n",
    "\n",
    "#gemma3:12b\n",
    "class GemmaOCR:\n",
    "    def init(self, model=\"gemma3:12b\", ollama_url=\"http://localhost:11434/api/generate\"):\n",
    "        self.model = model\n",
    "        self.ollama_url = ollama_url\n",
    "\n",
    "    def encode_image(self, image_path):\n",
    "        \"\"\"Convert image to base64 string.\"\"\"\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    def extract_text_from_image(self, image_path):\n",
    "        \"\"\"Send image to Gemma model for OCR-like extraction.\"\"\"\n",
    "        image_b64 = self.encode_image(image_path)\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": \"Extract and return all readable text from this image.\",\n",
    "            \"images\": [image_b64]\n",
    "        }\n",
    "\n",
    "        response = requests.post(self.ollama_url, json=payload, stream=True)\n",
    "        extracted_text = \"\"\n",
    "\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                try:\n",
    "                    data = json.loads(line.decode(\"utf-8\"))\n",
    "                    extracted_text += data.get(\"response\", \"\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        return extracted_text.strip()\n",
    "\n",
    "def process_pdf_with_gemma(pdf_path):\n",
    "    \"\"\"Main pipeline: PDF -> Images -> Gemma OCR -> Combined text.\"\"\"\n",
    "    extractor = PDFImageExtractor(pdf_path)\n",
    "    gemma_ocr = GemmaOCR()\n",
    "\n",
    "    image_paths = extractor.pdf_to_images()\n",
    "    all_text = \"\"\n",
    "\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        print(f\"\\nğŸ” Processing Page {idx + 1}...\")\n",
    "        page_text = gemma_ocr.extract_text_from_image(image_path)\n",
    "        all_text += f\"\\n\\n--- Page {idx + 1} ---\\n{page_text}\"\n",
    "\n",
    "    # Clean up images after extraction\n",
    "    extractor.cleanup_images()\n",
    "    return all_text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"cardinal.pdf\"   # change to your PDF file path\n",
    "    output_text = process_pdf_with_gemma(pdf_path)\n",
    "\n",
    "    # Use PDF filename (without extension) for output text file\n",
    "    base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    output_file = f\"{base_name}.txt\"\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output_text)\n",
    "\n",
    "    print(f\"\\nâœ… Extraction Complete! Text saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qwen\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import chromadb\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TextChunker:\n",
    "    def __init__(self, chunk_size: int, overlap: int):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.overlap = overlap\n",
    "\n",
    "    def chunk_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Splits the text into chunks with overlap.\"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        \n",
    "        for i in range(0, len(words), self.chunk_size - self.overlap):\n",
    "            chunk = words[i:i + self.chunk_size]\n",
    "            chunks.append(\" \".join(chunk))\n",
    "        \n",
    "        return chunks\n",
    "\n",
    "\n",
    "class EmbeddingProcessor:\n",
    "    def __init__(self, model=\"dengcao/Qwen3-Embedding-8B:Q8_0\", ollama_url=\"http://localhost:11434/api/generate\"):\n",
    "        self.model = model\n",
    "        self.ollama_url = ollama_url\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate embeddings for the provided text using Ollama.\"\"\"\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": f\"Embed the following text: {text}\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(self.ollama_url, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get(\"embedding\", [])\n",
    "        else:\n",
    "            raise Exception(f\"Error generating embedding: {response.text}\")\n",
    "\n",
    "\n",
    "class ChromaDBHandler:\n",
    "    def __init__(self, db_name=\"pdf_embeddings\"):\n",
    "        self.client = chromadb.Client()\n",
    "        self.collection = self.client.create_collection(db_name)\n",
    "\n",
    "    def store_embeddings(self, chunk_id: str, source: str, content_preview: str, embedding: List[float]):\n",
    "        \"\"\"Store embeddings in ChromaDB.\"\"\"\n",
    "        self.collection.add(\n",
    "            documents=[content_preview],\n",
    "            embeddings=[embedding],\n",
    "            metadatas=[{\"source\": source}],\n",
    "            ids=[chunk_id]\n",
    "        )\n",
    "\n",
    "    def query_embeddings(self, query_embedding: List[float], n_results=3):\n",
    "        \"\"\"Query the ChromaDB collection for similar embeddings.\"\"\"\n",
    "        results = self.collection.query(query_embeddings=query_embedding, n_results=n_results)\n",
    "        return results\n",
    "\n",
    "\n",
    "def process_pdf_embeddings(pdf_text_path, chunk_size=300, overlap=30):\n",
    "    # Read the text from the extracted file\n",
    "    with open(pdf_text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        pdf_text = f.read()\n",
    "\n",
    "    # Split the text into chunks\n",
    "    chunker = TextChunker(chunk_size=chunk_size, overlap=overlap)\n",
    "    chunks = chunker.chunk_text(pdf_text)\n",
    "\n",
    "    # Set up the Embedding processor and ChromaDB handler\n",
    "    embedding_processor = EmbeddingProcessor()\n",
    "    chromadb_handler = ChromaDBHandler()\n",
    "\n",
    "    # Embedding the chunks and storing in ChromaDB\n",
    "    all_embeddings = []\n",
    "    chunk_ids = []\n",
    "    for idx, chunk in enumerate(tqdm(chunks, desc=\"Embedding chunks\")):\n",
    "        chunk_id = f\"chunk_{idx + 1}\"\n",
    "        embedding = embedding_processor.embed_text(chunk)\n",
    "        content_preview = chunk[:100]  # Get first 100 characters for preview\n",
    "        chromadb_handler.store_embeddings(chunk_id, pdf_text_path, content_preview, embedding)\n",
    "\n",
    "        all_embeddings.append(embedding)\n",
    "        chunk_ids.append(chunk_id)\n",
    "\n",
    "    print(f\"\\nâœ… Successfully embedded {len(chunks)} chunks and stored in ChromaDB collection.\")\n",
    "\n",
    "    return chunk_ids\n",
    "\n",
    "\n",
    "def query_similar_embeddings(query_text, chunk_size=300, overlap=30):\n",
    "    # Generate the query embedding\n",
    "    chunker = TextChunker(chunk_size=chunk_size, overlap=overlap)\n",
    "    chunks = chunker.chunk_text(query_text)\n",
    "\n",
    "    embedding_processor = EmbeddingProcessor()\n",
    "    query_embedding = embedding_processor.embed_text(\" \".join(chunks))\n",
    "\n",
    "    # Set up ChromaDB handler for querying\n",
    "    chromadb_handler = ChromaDBHandler()\n",
    "    results = chromadb_handler.query_embeddings(query_embedding)\n",
    "\n",
    "    # Print query results\n",
    "    print(f\"\\nğŸ” Query Results:\")\n",
    "    for idx, result in enumerate(results[\"documents\"]):\n",
    "        print(f\"\\nğŸ”¹ ID: {results['ids'][idx]}\")\n",
    "        print(f\"ğŸ“„ Source: {result['metadata']['source']}\")\n",
    "        print(f\"ğŸ“ Content Preview: {result['document'][:200]}\")\n",
    "        print(f\"ğŸ“Š Distance: {results['distances'][idx]}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming that the text file is generated already\n",
    "    pdf_text_path = \"privacy_policy.txt\"  # Path to the text file with extracted text\n",
    "\n",
    "    # Process the PDF text and store embeddings\n",
    "    chunk_ids = process_pdf_embeddings(pdf_text_path)\n",
    "\n",
    "    # Example of querying the stored embeddings\n",
    "    query_text = \"What is the return policy for electronics?\"  # Example query\n",
    "    query_similar_embeddings(query_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e8664",
   "metadata": {},
   "source": [
    "## chatbot implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82665662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the chatbot! Type 'exit' to end the conversation.\n",
      "Full Response: model='qwen3:8b' created_at='2025-09-17T05:35:09.5152139Z' done=True done_reason='stop' total_duration=25776657600 load_duration=46179800 prompt_eval_count=9 prompt_eval_duration=323154100 eval_count=106 eval_duration=25406821400 message=Message(role='assistant', content='<think>\\nOkay, the user said \"hello\". I need to respond in a friendly and helpful manner. Let me start by acknowledging their greeting. Maybe say something like \"Hello!\" to be polite. Then, I should ask how I can assist them. That way, it opens up the conversation for them to ask questions or request help. Keep it simple and welcoming. Let me make sure the tone is positive and approachable. Alright, that should work.\\n</think>\\n\\nHello! ğŸ˜Š How can I assist you today?', thinking=None, images=None, tool_name=None, tool_calls=None)\n",
      "Bot: <think>\n",
      "Okay, the user said \"hello\". I need to respond in a friendly and helpful manner. Let me start by acknowledging their greeting. Maybe say something like \"Hello!\" to be polite. Then, I should ask how I can assist them. That way, it opens up the conversation for them to ask questions or request help. Keep it simple and welcoming. Let me make sure the tone is positive and approachable. Alright, that should work.\n",
      "</think>\n",
      "\n",
      "Hello! ğŸ˜Š How can I assist you today?\n",
      "Full Response: model='qwen3:8b' created_at='2025-09-17T05:39:34.4736854Z' done=True done_reason='stop' total_duration=254636876500 load_duration=45801000 prompt_eval_count=35 prompt_eval_duration=1177206000 eval_count=1042 eval_duration=253413366900 message=Message(role='assistant', content='<think>\\nOkay, the user asked about the color red. Let me start by recalling the basic properties of red. It\\'s a primary color in the traditional RYB color model, which is used in art. I should mention that it\\'s one of the primary colors in additive color models too, like in light, but maybe that\\'s more advanced. \\n\\nWait, the user might not need the technical details. Maybe start with the basics: what red is, its position in the color spectrum. Then talk about its symbolism. Red is often associated with emotions like passion, love, danger, and power. Different cultures might have different associations. For example, in Western cultures, red is a warning color, like stop signs, but in some Asian cultures, it\\'s a lucky color for weddings.\\n\\nAlso, think about the psychological effects. Red can stimulate the senses, increase heart rate, and is used in marketing to grab attention. Maybe mention some examples like red in branding, like Coca-Cola or Ferrari. \\n\\nDon\\'t forget the scientific aspects, like the wavelength of red light (around 620-750 nm). Also, the chemical aspect, like the pigment in red fruits or flowers. Maybe touch on historical uses, like in ancient art or clothing. \\n\\nWait, the user might be looking for a concise answer. Should I structure it into sections: definition, symbolism, cultural significance, psychological effects, scientific aspects, and examples? That way, it\\'s organized and covers all bases without being too overwhelming. \\n\\nAlso, check if there are any common misconceptions. For instance, red is sometimes confused with other colors, but it\\'s distinct. Maybe mention that red is a warm color, opposite to blue in the color wheel. \\n\\nI need to make sure the information is accurate. For example, the exact wavelength range for red light. Also, cultural examples: in China, red is used in weddings, while in some countries, it\\'s associated with danger. \\n\\nInclude some practical uses, like in traffic lights, where red is the stop signal. Maybe mention that red is also used in medical contexts, like in blood or as a warning sign. \\n\\nAvoid getting too technical unless the user asks for more details. Keep the explanation clear and accessible. Maybe end with a summary or a question to engage the user further. \\n\\nLet me put this all together in a coherent way, making sure each point flows naturally and covers the key aspects without being too verbose.\\n</think>\\n\\nRed is a vibrant, warm color that holds significant meaning across cultures, science, and psychology. Here\\'s a concise overview:\\n\\n### **1. Basic Properties**\\n- **Wavelength**: Red light has the longest wavelength in the visible spectrum, typically ranging from **620 to 750 nanometers**.\\n- **Primary Color**: In traditional color theory (RYB model), red is one of the three primary colors (alongside blue and yellow). In additive color models (like light), itâ€™s also a primary color.\\n\\n### **2. Symbolism and Cultural Significance**\\n- **Passion & Love**: Red is often linked to intense emotions like love, desire, and anger. Itâ€™s a common color in Valentineâ€™s Day and romantic contexts.\\n- **Danger & Warning**: In many cultures, red signals danger (e.g., stop signs, fire alarms) or signifies caution.\\n- **Lucky & Prosperity**: In Chinese culture, red is a symbol of good fortune, joy, and celebration (e.g., weddings, festivals).\\n- **Power & Authority**: Red is associated with royalty, power, and confidence (e.g., military uniforms, corporate branding).\\n\\n### **3. Psychological Effects**\\n- **Stimulating**: Red can energize, increase heart rate, and grab attention, making it popular in marketing and design.\\n- **Emotional Impact**: Itâ€™s often used to evoke urgency (e.g., sales promotions) or to highlight importance (e.g., warning signs).\\n\\n### **4. Scientific & Natural Occurrences**\\n- **Nature**: Red appears in fruits (berries, apples), flowers (roses, poppies), and animals (peacocks, flamingos).\\n- **Chemistry**: The pigment **betacyanin** gives red hues to plants, while **hemoglobin** in blood gives blood its red color.\\n\\n### **5. Practical Uses**\\n- **Design**: Red is used in branding (e.g., Coca-Cola, Ferrari) to convey energy or exclusivity.\\n- **Safety**: Traffic lights use red for \"stop,\" and itâ€™s a common color for emergency vehicles.\\n- **Art**: Red is a foundational color in art, often used to create contrast or emphasize focal points.\\n\\n### **6. Fun Facts**\\n- **Historical Use**: Ancient civilizations used red ochre for cave paintings and body paint.\\n- **Cultural Variations**: In some cultures, red is a color of mourning (e.g., in parts of Africa), while in others, itâ€™s a symbol of joy.\\n\\nWould you like to explore a specific aspect of red, like its role in art, science, or culture? ğŸ˜Š', thinking=None, images=None, tool_name=None, tool_calls=None)\n",
      "Bot: <think>\n",
      "Okay, the user asked about the color red. Let me start by recalling the basic properties of red. It's a primary color in the traditional RYB color model, which is used in art. I should mention that it's one of the primary colors in additive color models too, like in light, but maybe that's more advanced. \n",
      "\n",
      "Wait, the user might not need the technical details. Maybe start with the basics: what red is, its position in the color spectrum. Then talk about its symbolism. Red is often associated with emotions like passion, love, danger, and power. Different cultures might have different associations. For example, in Western cultures, red is a warning color, like stop signs, but in some Asian cultures, it's a lucky color for weddings.\n",
      "\n",
      "Also, think about the psychological effects. Red can stimulate the senses, increase heart rate, and is used in marketing to grab attention. Maybe mention some examples like red in branding, like Coca-Cola or Ferrari. \n",
      "\n",
      "Don't forget the scientific aspects, like the wavelength of red light (around 620-750 nm). Also, the chemical aspect, like the pigment in red fruits or flowers. Maybe touch on historical uses, like in ancient art or clothing. \n",
      "\n",
      "Wait, the user might be looking for a concise answer. Should I structure it into sections: definition, symbolism, cultural significance, psychological effects, scientific aspects, and examples? That way, it's organized and covers all bases without being too overwhelming. \n",
      "\n",
      "Also, check if there are any common misconceptions. For instance, red is sometimes confused with other colors, but it's distinct. Maybe mention that red is a warm color, opposite to blue in the color wheel. \n",
      "\n",
      "I need to make sure the information is accurate. For example, the exact wavelength range for red light. Also, cultural examples: in China, red is used in weddings, while in some countries, it's associated with danger. \n",
      "\n",
      "Include some practical uses, like in traffic lights, where red is the stop signal. Maybe mention that red is also used in medical contexts, like in blood or as a warning sign. \n",
      "\n",
      "Avoid getting too technical unless the user asks for more details. Keep the explanation clear and accessible. Maybe end with a summary or a question to engage the user further. \n",
      "\n",
      "Let me put this all together in a coherent way, making sure each point flows naturally and covers the key aspects without being too verbose.\n",
      "</think>\n",
      "\n",
      "Red is a vibrant, warm color that holds significant meaning across cultures, science, and psychology. Here's a concise overview:\n",
      "\n",
      "### **1. Basic Properties**\n",
      "- **Wavelength**: Red light has the longest wavelength in the visible spectrum, typically ranging from **620 to 750 nanometers**.\n",
      "- **Primary Color**: In traditional color theory (RYB model), red is one of the three primary colors (alongside blue and yellow). In additive color models (like light), itâ€™s also a primary color.\n",
      "\n",
      "### **2. Symbolism and Cultural Significance**\n",
      "- **Passion & Love**: Red is often linked to intense emotions like love, desire, and anger. Itâ€™s a common color in Valentineâ€™s Day and romantic contexts.\n",
      "- **Danger & Warning**: In many cultures, red signals danger (e.g., stop signs, fire alarms) or signifies caution.\n",
      "- **Lucky & Prosperity**: In Chinese culture, red is a symbol of good fortune, joy, and celebration (e.g., weddings, festivals).\n",
      "- **Power & Authority**: Red is associated with royalty, power, and confidence (e.g., military uniforms, corporate branding).\n",
      "\n",
      "### **3. Psychological Effects**\n",
      "- **Stimulating**: Red can energize, increase heart rate, and grab attention, making it popular in marketing and design.\n",
      "- **Emotional Impact**: Itâ€™s often used to evoke urgency (e.g., sales promotions) or to highlight importance (e.g., warning signs).\n",
      "\n",
      "### **4. Scientific & Natural Occurrences**\n",
      "- **Nature**: Red appears in fruits (berries, apples), flowers (roses, poppies), and animals (peacocks, flamingos).\n",
      "- **Chemistry**: The pigment **betacyanin** gives red hues to plants, while **hemoglobin** in blood gives blood its red color.\n",
      "\n",
      "### **5. Practical Uses**\n",
      "- **Design**: Red is used in branding (e.g., Coca-Cola, Ferrari) to convey energy or exclusivity.\n",
      "- **Safety**: Traffic lights use red for \"stop,\" and itâ€™s a common color for emergency vehicles.\n",
      "- **Art**: Red is a foundational color in art, often used to create contrast or emphasize focal points.\n",
      "\n",
      "### **6. Fun Facts**\n",
      "- **Historical Use**: Ancient civilizations used red ochre for cave paintings and body paint.\n",
      "- **Cultural Variations**: In some cultures, red is a color of mourning (e.g., in parts of Africa), while in others, itâ€™s a symbol of joy.\n",
      "\n",
      "Would you like to explore a specific aspect of red, like its role in art, science, or culture? ğŸ˜Š\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Function to initialize and interact with the chatbot\n",
    "def chat():\n",
    "    print(\"Welcome to the chatbot! Type 'exit' to end the conversation.\")\n",
    "    \n",
    "    history = []  \n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        \n",
    "        history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        \n",
    "        response = ollama.chat(model=\"qwen3:8b\", messages=history)\n",
    "        \n",
    "        # Print the whole response to inspect its structure\n",
    "        print(\"Full Response:\", response)\n",
    "        \n",
    "        # Extract the assistant's response from the message\n",
    "        try:\n",
    "            chatbot_reply = response.message.content if response.message else \"No reply\"\n",
    "            print(f\"Bot: {chatbot_reply}\")\n",
    "        except AttributeError as e:\n",
    "            print(f\"Error: Missing expected attribute {e} in the response.\")\n",
    "        \n",
    "        # Add the assistant's response to history\n",
    "        history.append({\"role\": \"assistant\", \"content\": chatbot_reply})\n",
    "\n",
    "# Run the chatbot function\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n",
    "\n",
    "#worked but need time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01453f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Chatbot (qwen3:8b) is ready! Type 'exit' to quit.\n",
      "\n",
      "ğŸ¤– Bot: <think>\n",
      "Okay, the user said \"hello\". I need to respond in a friendly and concise way. Let me make sure to greet them back and offer help. Maybe something like, \"Hello! How can I assist you today?\" That's straightforward and opens the door for them to ask anything they need. I should keep it simple and positive.\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today? ğŸ˜Š\n",
      "ğŸ¤– Bot: <think>\n",
      "Okay, the user asked for a short explanation about a full moon. Let me recall what I know. A full moon occurs when the Moon is on the opposite side of Earth from the Sun, so the Sun's light reflects off the Moon's surface and is visible from Earth. This happens once every lunar month, which is about 29.5 days. During a full moon, the Moon appears fully illuminated. I should mention the phases leading up to it, like the waning gibbous and then the full moon. Also, maybe note that it's when the Moon is farthest from Earth in its orbit, but wait, no, the full moon is actually when it's at apogee or perigee? Wait, no, the distance varies, but the full moon's visibility is more about the alignment. Maybe I should focus on the basic explanation without getting too technical. Keep it simple and concise. Make sure to highlight the alignment, the illumination, and the frequency. Avoid any unnecessary details. Let me check if I got the phases right. After the last quarter, it's the waning gibbous, then full moon. Yeah, that's correct. Alright, time to put it all together in a short, clear response.\n",
      "</think>\n",
      "\n",
      "A full moon occurs when the Moon is on the opposite side of Earth from the Sun, fully illuminated and visible from Earth. It happens once every lunar month (about 29.5 days) during the phase when the Moon's orbit aligns with the Sun and Earth, creating a bright, round appearance in the night sky. ğŸŒ•âœ¨\n",
      "ğŸ¤– Bot: <think>\n",
      "Okay, the user asked about the red color. Let me think about how to approach this. They might be interested in the color itself, its symbolism, or maybe something else like the red color in nature or technology.\n",
      "\n",
      "First, I should explain what red is in terms of color theory. Red is a primary color, part of the visible spectrum. It has a wavelength between 620-750 nm. Then, mention its psychological effectsâ€”like excitement, danger, or passion. \n",
      "\n",
      "Also, cultural symbolism is important. In many cultures, red represents luck, happiness, or celebration. But it can also symbolize danger or warning. Maybe include examples like the Chinese New Year, Valentine's Day, or stop signs.\n",
      "\n",
      "I should keep it concise but cover the main points. The user might be looking for a quick overview without too much detail. Let me make sure to mention both the scientific aspect and the cultural meanings. Avoid jargon so it's easy to understand. Check if there's anything else they might need, but since the query was short, stick to the basics.\n",
      "</think>\n",
      "\n",
      "Red is a primary color in the visible spectrum, with a wavelength of about 620â€“750 nanometers. It symbolizes energy, passion, danger, or love across cultures. In nature, it appears in flowers, blood, and sunsets, and in technology, itâ€™s used for alerts (like stop signs) or to grab attention. ğŸŒ¹ğŸ”¥\n",
      "ğŸ¤– Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "#demo 2 chatbot\n",
    "import ollama\n",
    "\n",
    "def chat_with_bot():\n",
    "    # Define your system prompt here\n",
    "    system_prompt = \"You are a helpful assistant that always replies in a friendly and concise way.\"\n",
    "\n",
    "    print(\"ğŸ¤– Chatbot (qwen3:8b) is ready! Type 'exit' to quit.\\n\")\n",
    "\n",
    "    # Store conversation history\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"ğŸ¤– Bot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Add user message to conversation\n",
    "        conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Send conversation to Ollama\n",
    "        response = ollama.chat(\n",
    "            model=\"qwen3:8b\",\n",
    "            messages=conversation\n",
    "            # temperature=0.7,\n",
    "            # max_token=512,\n",
    "            # top_p=0.9,\n",
    "            # frequency_penalty=0,\n",
    "            # presence_penalty=0.6,\n",
    "            # stop=None,\n",
    "            # stream=False,\n",
    "            # n=1,\n",
    "        )\n",
    "\n",
    "        bot_reply = response[\"message\"][\"content\"]\n",
    "        print(\"ğŸ¤– Bot:\", bot_reply)\n",
    "\n",
    "        # Save bot reply in conversation history\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_bot()\n",
    " \n",
    "\n",
    " #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012bf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Chatbot (qwen3:8b) is ready! Type 'exit' to quit.\n",
      "\n",
      "ğŸ¤– Bot: ğŸ“„ Chunk 4: you can opt out of targeted advertising through your browser settings, or through your device settings, such as on an iPhone or Android phone. You can also opt out of targeted advertising by using the opt-out links provided by the advertising network. ...\n",
      "ğŸ“„ Chunk 5: You can opt out of interest-based ads by visiting the Network Advertising Initiative's opt-out page. This will opt you out of receiving targeted ads from many of the major ad networks. ...\n",
      "\n",
      "Based on the information provided, here's the answer to your question:\n",
      "\n",
      "Yes, you can control the type of advertisements you see or choose to opt out entirely. Here are the methods you can use:\n",
      "\n",
      "1. **Browser or Device Settings**: You can opt out of targeted advertising through your browser settings or device settings (such as on an iPhone or Android phone). These settings allow you to manage your ad preferences and limit the types of ads you see.\n",
      "\n",
      "2. **Advertising Network Opt-Out Links**: Many advertising networks provide opt-out links that you can use to stop receiving targeted ads from them. For example, you can use the opt-out links provided by the advertising network to manage your ad preferences.\n",
      "\n",
      "3. **Network Advertising Initiative (NAI) Opt-Out Page**: You can opt out of interest-based ads by visiting the Network Advertising Initiative's opt-out page. This will opt you out of receiving targeted ads from many of the major ad networks.\n",
      "\n",
      "By using these methods, you can have more control over the advertisements you see online. If you have any further questions, feel free to ask!\n",
      "</think>\n",
      "\n",
      "Yes, you can control the type of advertisements you see or opt out entirely. Here are the key methods:\n",
      "\n",
      "1. **Browser/Device Settings**:  \n",
      "   - Use your browser's privacy settings (e.g., Chrome, Firefox) to manage ad preferences.  \n",
      "   - On mobile devices (iPhone/Android), adjust settings to limit tracking or block ads.  \n",
      "\n",
      "2. **Advertising Network Opt-Outs**:  \n",
      "   - Many platforms provide opt-out links (e.g., Google, Facebook) to stop targeted ads.  \n",
      "\n",
      "3. **Network Advertising Initiative (NAI) Opt-Out**:  \n",
      "   - Visit [NAIâ€™s opt-out page](https://optout.networkadvertising.org/) to block interest-based ads from major networks like Google, Facebook, and others.  \n",
      "\n",
      "These options let you customize or disable targeted advertising based on your preferences. Let me know if you need help finding specific opt-out links!\n",
      "ğŸ¤– Bot: ğŸ“„ Chunk 4: you can opt out of targeted advertising through your browser settings, or through your device settings, such as on an iPhone or Android phone. You can also opt out of targeted advertising by using the opt-out links provided by the advertising network. ...\n",
      "ğŸ“„ Chunk 5: You can opt out of interest-based ads by visiting the Network Advertising Initiative's opt-out page. This will opt you out of receiving targeted ads from many of the major ad networks. ...\n",
      "\n",
      "Based on the information provided, here's the answer to your question:\n",
      "\n",
      "Shopify complies with data protection laws for residents in the European Economic Area (EEA), the UK, and Switzerland by adhering to the General Data Protection Regulation (GDPR) and other relevant regulations. Here's how they ensure compliance:\n",
      "\n",
      "1. **Lawful Basis for Data Processing**: Shopify processes personal data based on legal obligations, such as complying with applicable laws or responding to valid legal processes, including requests from law enforcement or government agencies.\n",
      "\n",
      "2. **Data Retention**: They retain personal data only for as long as necessary, such as the duration of your account or while you use their services, and they provide mechanisms for you to request data deletion or modification.\n",
      "\n",
      "3. **Transparency and Consent**: Shopify ensures transparency by providing clear information about how data is collected and used. They also allow users to opt out of targeted advertising through browser settings, device settings, or opt-out links provided by advertising networks.\n",
      "\n",
      "4. **Data Security**: They implement measures to protect against security threats, fraud, and unauthorized access, ensuring the safety of user data.\n",
      "\n",
      "By following these practices, Shopify ensures that it meets the data protection requirements for residents in the EEA, UK, and Switzerland. If you need more specific details about their data handling, you can review their official privacy policy or contact their support team.\n",
      "ğŸ¤– Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# import ollama\n",
    "# import chromadb\n",
    "# from chromadb.config import Settings\n",
    "\n",
    "# class KnowledgeBase:\n",
    "#     def __init__(self, db_path=\"./chroma_db\"):\n",
    "#         # Initialize ChromaDB client\n",
    "#         self.client = chromadb.PersistentClient(path=db_path)\n",
    "#         self.collection_name = \"pdf_embeddings\"\n",
    "        \n",
    "#         # Create or get collection\n",
    "#         self.collection = self.client.get_or_create_collection(\n",
    "#             name=self.collection_name,\n",
    "#             metadata={\"description\": \"PDF text embeddings\"}\n",
    "#         )\n",
    "\n",
    "#     def search_similar(self, query, n_results=3):\n",
    "#         \"\"\"Search for similar chunks in the ChromaDB collection.\"\"\"\n",
    "#         results = self.collection.query(\n",
    "#             query_texts=[query],\n",
    "#             n_results=n_results\n",
    "#         )\n",
    "#         return results\n",
    "\n",
    "\n",
    "# def chat_with_bot():\n",
    "#     # Initialize ChromaDB knowledge base\n",
    "#     kb = KnowledgeBase()\n",
    "\n",
    "#     # Define your system prompt\n",
    "#     system_prompt = \"You are a helpful assistant that always replies in a friendly and concise way.\"\n",
    "\n",
    "#     print(\"ğŸ¤– Chatbot (qwen3:8b) is ready! Type 'exit' to quit.\\n\")\n",
    "\n",
    "#     # Store conversation history\n",
    "#     conversation = [\n",
    "#         {\"role\": \"system\", \"content\": system_prompt}\n",
    "#     ]\n",
    "\n",
    "#     while True:\n",
    "#         user_input = input(\"You: \")\n",
    "#         if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "#             print(\"ğŸ¤– Bot: Goodbye!\")\n",
    "#             break\n",
    "\n",
    "#         # Add user message to conversation\n",
    "#         conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "#         # Search for relevant information from the knowledge base\n",
    "#         kb_results = kb.search_similar(user_input)\n",
    "\n",
    "#         # Combine the knowledge base results into the conversation\n",
    "#         kb_response = \"\"\n",
    "        \n",
    "#         # Process and include top results from ChromaDB\n",
    "#         for idx, document in enumerate(kb_results['documents'][0]):\n",
    "#             kb_response += f\"ğŸ“„ Chunk {idx+1}: {document[:300]}...\\n\"\n",
    "        \n",
    "#         # If there are results, include them in the conversation\n",
    "#         if kb_response:\n",
    "#             knowledge_base_message = f\"Here is some relevant information I found from the knowledge base:\\n{kb_response}\"\n",
    "#         else:\n",
    "#             knowledge_base_message = \"I couldn't find anything relevant in my knowledge base.\"\n",
    "\n",
    "#         # Add KB response to conversation\n",
    "#         conversation.append({\"role\": \"assistant\", \"content\": knowledge_base_message})\n",
    "\n",
    "#         # Send conversation to Ollama for further processing and response\n",
    "#         response = ollama.chat(\n",
    "#             model=\"qwen3:8b\",\n",
    "#             messages=conversation\n",
    "#         )\n",
    "\n",
    "#         bot_reply = response[\"message\"][\"content\"]\n",
    "#         print(\"ğŸ¤– Bot:\", bot_reply)\n",
    "\n",
    "#         # Save bot reply in conversation history\n",
    "#         conversation.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     chat_with_bot()\n",
    "\n",
    "\n",
    "import ollama\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "\n",
    "class KnowledgeBase:\n",
    "    def __init__(self, db_path=\"./chroma_db\"):\n",
    "        # Initialize ChromaDB client\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection_name = \"pdf_embeddings\"\n",
    "        \n",
    "        # Create or get collection\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=self.collection_name,\n",
    "            metadata={\"description\": \"PDF text embeddings\"}\n",
    "        )\n",
    "\n",
    "    def search_similar(self, query, n_results=3):\n",
    "        \"\"\"Search for similar chunks in the ChromaDB collection.\"\"\"\n",
    "        results = self.collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        \n",
    "        # Return documents and their metadata separately\n",
    "        documents = results['documents'][0]\n",
    "        metadatas = results['metadatas'][0]\n",
    "        return documents, metadatas\n",
    "\n",
    "def chat_with_bot():\n",
    "    # Initialize ChromaDB knowledge base\n",
    "    kb = KnowledgeBase()\n",
    "\n",
    "    # Define your system prompt\n",
    "    system_prompt = \"\"\"\n",
    "    You are a helpful assistant designed to assist with specific topics. \n",
    "    Your responses should be informative, concise, and polite. \n",
    "    You have access to a knowledge base that contains information from PDF documents, which can help provide accurate answers to user queries.\n",
    "    If the user asks for help related to the content in the PDFs, retrieve the most relevant chunks and incorporate them into your responses.\n",
    "    Always aim to be clear and direct in your explanations, and provide examples or context where possible.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ğŸ¤– Chatbot (qwen3:8b) is ready! Type 'exit' to quit.\\n\")\n",
    "\n",
    "    # Store conversation history\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"ğŸ¤– Bot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Add user message to conversation\n",
    "        conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Search for relevant information from the knowledge base\n",
    "        kb_documents, kb_metadatas = kb.search_similar(user_input)\n",
    "\n",
    "        # Combine the knowledge base results into the conversation\n",
    "        kb_response = \"\"\n",
    "        \n",
    "        # Process and include top results from ChromaDB\n",
    "        if kb_documents:\n",
    "            kb_response = \"Here is some relevant information I found from the knowledge base:\\n\"\n",
    "            for idx, document in enumerate(kb_documents):\n",
    "                kb_response += f\"ğŸ“„ Chunk {idx+1}: {document[:300]}...\\n\"\n",
    "        \n",
    "        if not kb_documents:\n",
    "            kb_response = \"I couldn't find anything relevant in my knowledge base.\"\n",
    "        \n",
    "        # Add KB response to conversation\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": kb_response})\n",
    "\n",
    "        # Send conversation to Ollama for further processing and response\n",
    "        response = ollama.chat(\n",
    "            model=\"qwen3:8b\",\n",
    "            messages=conversation\n",
    "        )\n",
    "\n",
    "        bot_reply = response[\"message\"][\"content\"]\n",
    "        print(\"ğŸ¤– Bot:\", bot_reply)\n",
    "\n",
    "        # Save bot reply in conversation history\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_bot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66fd8e",
   "metadata": {},
   "source": [
    "## merge code all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eef2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing EasyOCR...\n",
      "EasyOCR initialized successfully!\n",
      "Step 1: Converting PDF to images...\n",
      "Converting 7 pages to images...\n",
      "âœ… Page 1 saved as pdf_images\\page_1.png\n",
      "âœ… Page 2 saved as pdf_images\\page_2.png\n",
      "âœ… Page 3 saved as pdf_images\\page_3.png\n",
      "âœ… Page 4 saved as pdf_images\\page_4.png\n",
      "âœ… Page 5 saved as pdf_images\\page_5.png\n",
      "âœ… Page 6 saved as pdf_images\\page_6.png\n",
      "âœ… Page 7 saved as pdf_images\\page_7.png\n",
      "Step 2: Extracting text from images...\n",
      "Processing page 1/7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Busra\\Melikoz\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 2/7...\n",
      "Processing page 3/7...\n",
      "Processing page 4/7...\n",
      "Processing page 5/7...\n",
      "Processing page 6/7...\n",
      "Processing page 7/7...\n",
      "ğŸ—‘ï¸ Deleted temporary folder: pdf_images\n",
      "Extracted text saved to: merge__extracted_text.txt\n",
      "âœ… Successfully embedded 5 chunks from merge__extracted_text.txt\n",
      "ğŸ¤– Chatbot (qwen3:8b) is ready! Type 'exit' to quit.\n",
      "\n",
      "ğŸ¤– Bot: ğŸ“„ Chunk 4: We may share your personal data with third parties for the purposes of providing our services or services offered by our Merchants, including: (1) our service providers who perform services on our behalf, such as hosting, payment processing, customer service, and marketing; (2) our parent company, subsidiaries, and affiliates, including Shopify, Shopify Payments, and Shopify Plus; (3) merchants who are part of the Shopify platform, including those who sell products or services on the Shopify platform; (4) third parties that provide products or services that integrate with Shopify, such...\n",
      "ğŸ“„ Chunk 5: Shopify's privacy policy is designed to help you understand how we collect, use, and share your personal data. This policy is subject to change over time, and we may update it without prior notice. If we make changes to this policy, we will update it on our website and notify you of the changes through our website or other means of communication. We encourage you to review this policy regularly to ensure that you are aware of the latest information regarding your personal data.\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today? If you have any questions about privacy policies, data usage, or need help with something else, feel free to ask! ğŸ˜Š\n",
      "ğŸ¤– Bot: ğŸ“„ Chunk 4: We may share your personal data with third parties for the purposes of providing our services or services offered by our Merchants, including: (1) our service providers who perform services on our behalf, such as hosting, payment processing, customer service, and marketing; (2) our parent company, subsidiaries, and affiliates, including Shopify, Shopify Payments, and Shopify Plus; (3) merchants who are part of the Shopify platform, including those who sell products or services on the Shopify platform; (4) third parties that provide products or services that integrate with Shopify, such...\n",
      "ğŸ“„ Chunk 5: Shopify's privacy policy is designed to help you understand how we collect, use, and share your personal data. This policy is subject to change over time, and we may update it without prior notice. If we make changes to this policy, we will update it on our website and notify you of the changes through our website or other means of communication. We encourage you to review this policy regularly to ensure that you are aware of the latest information regarding your personal data.\n",
      "</think>\n",
      "\n",
      "Shopify complies with data protection laws, including the **General Data Protection Regulation (GDPR)** in the **European Economic Area (EEA)**, the **UK GDPR** in the **UK**, and the **Swiss Data Protection Act** in **Switzerland**, through several key measures:\n",
      "\n",
      "### 1. **Legal Basis for Data Processing**\n",
      "   - Shopify processes personal data based on **lawful bases** such as:\n",
      "     - **Consent** (where required).\n",
      "     - **Contractual obligations** (e.g., providing Shopify services).\n",
      "     - **Legal compliance** (e.g., responding to law enforcement or government requests, as outlined in their privacy policy).\n",
      "     - **Legitimate interests** (e.g., ensuring security, preventing fraud, or protecting public safety).\n",
      "\n",
      "### 2. **Data Transfer and International Transfers**\n",
      "   - Shopify ensures compliance with **international data transfer regulations** (e.g., GDPR Article 44/45) by:\n",
      "     - Using **standard contractual clauses (SCCs)** for data transfers to third-party service providers.\n",
      "     - Ensuring that data transfers to countries outside the EEA/UK/Switzerland meet adequacy decisions or are covered by SCCs.\n",
      "\n",
      "### 3. **User Rights and Transparency**\n",
      "   - Shopify grants users **rights under data protection laws**, such as:\n",
      "     - **Access** to their personal data.\n",
      "     - **Rectification** of inaccuracies.\n",
      "     - **Erasure** (right to be forgotten) under certain conditions.\n",
      "     - **Data portability**.\n",
      "   - They also provide **clear privacy notices** and allow users to **opt out of data sharing** where applicable.\n",
      "\n",
      "### 4. **Security and Accountability**\n",
      "   - Shopify implements **technical and organizational measures** to protect data, such as encryption, access controls, and regular audits.\n",
      "   - They are **accountable** for data processing activities and may appoint a **Data Protection Officer (DPO)** where required.\n",
      "\n",
      "### 5. **Compliance Updates**\n",
      "   - Shopifyâ€™s privacy policy is **regularly updated** to reflect changes in data protection laws, and users are notified of material changes.\n",
      "\n",
      "For more details, you can review Shopifyâ€™s full [Privacy Policy](https://www.shopify.com/legal/privacy) or contact their legal team directly. Let me know if you need further clarification! ğŸ˜Š\n",
      "ğŸ¤– Bot: ğŸ“„ Chunk 4: We may share your personal data with third parties for the purposes of providing our services or services offered by our Merchants, including: (1) our service providers who perform services on our behalf, such as hosting, payment processing, customer service, and marketing; (2) our parent company, subsidiaries, and affiliates, including Shopify, Shopify Payments, and Shopify Plus; (3) merchants who are part of the Shopify platform, including those who sell products or services on the Shopify platform; (4) third parties that provide products or services that integrate with Shopify, such...\n",
      "ğŸ“„ Chunk 5: Shopify's privacy policy is designed to help you understand how we collect, use, and share your personal data. This policy is subject to change over time, and we may update it without prior notice. If we make changes to this policy, we will update it on our website and notify you of the changes through our website or other means of communication. We encourage you to review this policy regularly to ensure that you are aware of the latest information regarding your personal data.\n",
      "</think>\n",
      "\n",
      "Shopify notifies users of significant changes to their **Privacy Policy** through the following methods:\n",
      "\n",
      "### 1. **Website Updates**\n",
      "   - Shopify updates the **Privacy Policy** directly on their website ([https://www.shopify.com/legal/privacy](https://www.shopify.com/legal/privacy)). \n",
      "   - Changes are highlighted to make them easy to spot.\n",
      "\n",
      "### 2. **Email Notifications**\n",
      "   - If you have an account or are a merchant using Shopify services, you may receive **email notifications** when major updates are made to the policy. These emails typically include a link to the revised policy.\n",
      "\n",
      "### 3. **In-App or Platform Alerts**\n",
      "   - For users on the Shopify platform (e.g., merchants or app developers), Shopify may display **in-app alerts** or notifications directing you to the updated policy.\n",
      "\n",
      "### 4. **General Communication**\n",
      "   - Shopify may also announce policy changes through **blog posts, newsletters, or social media channels** to keep users informed.\n",
      "\n",
      "### 5. **Regular Review Encouragement**\n",
      "   - Shopify encourages users to **review the policy regularly** to stay updated on how their data is handled.\n",
      "\n",
      "If youâ€™re unsure about updates, always check the **latest version of the Privacy Policy** on Shopifyâ€™s official website. Let me know if youâ€™d like help locating it! ğŸ˜Š\n",
      "ğŸ¤– Bot: ğŸ“„ Chunk 4: We may share your personal data with third parties for the purposes of providing our services or services offered by our Merchants, including: (1) our service providers who perform services on our behalf, such as hosting, payment processing, customer service, and marketing; (2) our parent company, subsidiaries, and affiliates, including Shopify, Shopify Payments, and Shopify Plus; (3) merchants who are part of the Shopify platform, including those who sell products or services on the Shopify platform; (4) third parties that provide products or services that integrate with Shopify, such...\n",
      "ğŸ“„ Chunk 5: Shopify's privacy policy is designed to help you understand how we collect, use, and share your personal data. This policy is subject to change over time, and we may update it without prior notice. If we make changes to this policy, we will update it on our website and notify you of the changes through our website or other means of communication. We encourage you to review this policy regularly to ensure that you are aware of the latest information regarding your personal data.\n",
      "</think>\n",
      "\n",
      "Shopify **does not handle shipping or logistics directly**â€”it is the **merchants** (store owners) who manage shipping, inventory, and delivery. Whether shipping to **Bangladesh** is possible depends on the **merchantâ€™s shipping policies** and **logistics providers** they use. Hereâ€™s how it works:\n",
      "\n",
      "### 1. **Merchant Responsibility**\n",
      "   - Merchants on Shopify can ship to **Bangladesh** if they:\n",
      "     - Offer **international shipping**.\n",
      "     - Partner with **logistics companies** that deliver to Bangladesh (e.g., DHL, FedEx, Aramex, or local couriers like BD Express, Grameen Phone, or Naptol).\n",
      "     - Have **proper customs documentation** and comply with **import regulations** for Bangladesh.\n",
      "\n",
      "### 2. **Shopifyâ€™s Role**\n",
      "   - Shopify provides **tools for merchants** to manage shipping, track orders, and integrate with third-party logistics providers.\n",
      "   - It does **not guarantee** shipping to Bangladesh or handle delivery logistics.\n",
      "\n",
      "### 3. **Challenges for Bangladesh**\n",
      "   - Shipping to Bangladesh may involve **customs delays**, **higher shipping costs**, and **logistical complexities** due to the countryâ€™s geography and infrastructure.\n",
      "   - Merchants must ensure compliance with **Bangladeshi import laws** (e.g., product restrictions, duties, and taxes).\n",
      "\n",
      "### 4. **How to Check**\n",
      "   - Look for **shipping options** on the product page (e.g., \"Ship to Bangladesh\").\n",
      "   - Contact the merchant directly to confirm **availability** and **delivery timelines**.\n",
      "\n",
      "If youâ€™re a buyer, always verify with the seller before purchasing. If youâ€™re a merchant, Shopifyâ€™s **Shipping & Fulfillment tools** can help manage international orders. Let me know if you need guidance on either role! ğŸ˜Š\n",
      "ğŸ¤– Bot: ğŸ“„ Chunk 4: We may share your personal data with third parties for the purposes of providing our services or services offered by our Merchants, including: (1) our service providers who perform services on our behalf, such as hosting, payment processing, customer service, and marketing; (2) our parent company, subsidiaries, and affiliates, including Shopify, Shopify Payments, and Shopify Plus; (3) merchants who are part of the Shopify platform, including those who sell products or services on the Shopify platform; (4) third parties that provide products or services that integrate with Shopify, such...\n",
      "ğŸ“„ Chunk 5: Shopify's privacy policy is designed to help you understand how we collect, use, and share your personal data. This policy is subject to change over time, and we may update it without prior notice. If we make changes to this policy, we will update it on our website and notify you of the changes through our website or other means of communication. We encourage you to review this policy regularly to ensure that you are aware of the latest information regarding your personal data.\n",
      "</think>\n",
      "\n",
      "The ability to **return a parcel** and the **conditions** for returns depend on the **merchantâ€™s return policy**, not Shopify itself. Shopify provides tools for merchants to manage returns, but **return policies are set by individual sellers**. Hereâ€™s what you need to know:\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“¦ **General Return Conditions (Merchant-Defined):**\n",
      "1. **Timeframe**:\n",
      "   - Most merchants allow returns within **14â€“30 days** of delivery, but this varies.\n",
      "   - Check the **product page** or **order confirmation email** for specific details.\n",
      "\n",
      "2. **Eligibility**:\n",
      "   - Items must be **unused** and in **original condition** (e.g., tags intact, packaging undamaged).\n",
      "   - Some merchants may **exclude sale items, custom orders, or perishable goods**.\n",
      "\n",
      "3. **Refund Method**:\n",
      "   - Refunds are typically issued to the **original payment method** (e.g., credit card, PayPal).\n",
      "   - Some sellers may offer **store credit** or **exchanges** instead.\n",
      "\n",
      "4. **Shipping Responsibility**:\n",
      "   - Merchants may require you to **cover return shipping costs** or offer **free returns**.\n",
      "   - Check the **return instructions** provided by the seller.\n",
      "\n",
      "5. **Customs or Import Restrictions**:\n",
      "   - If the item was shipped to **Bangladesh**, additional **customs duties or import taxes** may apply, and the seller may not refund these fees.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ› ï¸ **How to Initiate a Return:**\n",
      "1. **Contact the Merchant**:\n",
      "   - Use the **contact form**, **chat**, or **email** provided in the order confirmation.\n",
      "   - Request a **return authorization** or **refund**.\n",
      "\n",
      "2. **Follow Instructions**:\n",
      "   - Ship the item back using the **prepaid label** (if provided) or your own shipping method.\n",
      "   - Keep **proof of shipping** (e.g., tracking number).\n",
      "\n",
      "3. **Wait for Processing**:\n",
      "   - Merchants typically process refunds within **5â€“10 business days** after receiving the returned item.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“Œ **Shopifyâ€™s Role**:\n",
      "- Shopify does **not enforce return policies**; it only provides a **platform** for merchants to manage returns.\n",
      "- Merchants can use Shopifyâ€™s **Return Management tools** to streamline the process (e.g., tracking returns, issuing refunds).\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… **What to Do If Youâ€™re Unsure**:\n",
      "- Check the **product page** for return policies.\n",
      "- Look for **FAQs** or **contact information** in your order confirmation email.\n",
      "- Reach out to the **merchant directly** for clarity.\n",
      "\n",
      "If youâ€™re a merchant, Shopifyâ€™s **Return Management** tools can help automate and simplify the return process. Let me know if you need help with either buyer or seller scenarios! ğŸ˜Š\n",
      "ğŸ¤– Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# import easyocr\n",
    "# import fitz  # PyMuPDF\n",
    "# import chromadb\n",
    "# import ollama\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# from typing import List, Tuple\n",
    "# from chromadb.config import Settings\n",
    "\n",
    "# # EasyOCR and PDF Processing Class\n",
    "# class PDFOCRProcessor:\n",
    "#     def __init__(self, languages=['en'], gpu=False):\n",
    "#         print(\"Initializing EasyOCR...\")\n",
    "#         self.reader = easyocr.Reader(languages, gpu=gpu)\n",
    "#         print(\"EasyOCR initialized successfully!\")\n",
    "\n",
    "#     def pdf_to_images(self, pdf_path: str, output_dir: str = None, dpi: int = 200) -> List[str]:\n",
    "#         if not os.path.exists(pdf_path):\n",
    "#             raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "#         if output_dir:\n",
    "#             os.makedirs(output_dir, exist_ok=True)\n",
    "#         doc = fitz.open(pdf_path)\n",
    "#         image_paths = []\n",
    "#         print(f\"Converting {len(doc)} pages to images...\")\n",
    "#         for page_num in range(len(doc)):\n",
    "#             page = doc[page_num]\n",
    "#             mat = fitz.Matrix(dpi/72, dpi/72)\n",
    "#             pix = page.get_pixmap(matrix=mat)\n",
    "#             img_data = pix.tobytes(\"png\")\n",
    "#             img = Image.open(io.BytesIO(img_data)) if 'io' in globals() else None\n",
    "#             if img is None:\n",
    "#                 img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "#             if output_dir:\n",
    "#                 image_path = os.path.join(output_dir, f\"page_{page_num + 1}.png\")\n",
    "#                 img.save(image_path, \"PNG\")\n",
    "#                 image_paths.append(image_path)\n",
    "#             else:\n",
    "#                 image_path = f\"temp_page_{page_num + 1}.png\"\n",
    "#                 img.save(image_path, \"PNG\")\n",
    "#                 image_paths.append(image_path)\n",
    "#             print(f\"Page {page_num + 1} converted to image\")\n",
    "#         doc.close()\n",
    "#         return image_paths\n",
    "\n",
    "#     def enhance_image_for_ocr(self, image_path: str) -> np.ndarray:\n",
    "#         img = cv2.imread(image_path)\n",
    "#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#         denoised = cv2.fastNlMeansDenoising(gray)\n",
    "#         thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "#         return thresh\n",
    "\n",
    "#     def extract_text_from_image(self, image_path: str, enhance: bool = True) -> List[Tuple[str, float]]:\n",
    "#         if enhance:\n",
    "#             img = self.enhance_image_for_ocr(image_path)\n",
    "#             results = self.reader.readtext(img)\n",
    "#         else:\n",
    "#             results = self.reader.readtext(image_path)\n",
    "#         text_results = [(result[1], result[2]) for result in results]\n",
    "#         return text_results\n",
    "\n",
    "#     def process_pdf(self, pdf_path: str, output_dir: str = None, enhance_images: bool = True, confidence_threshold: float = 0.5) -> dict:\n",
    "#         results = {'pdf_path': pdf_path, 'pages': [], 'total_pages': 0, 'extracted_text': ''}\n",
    "#         try:\n",
    "#             print(\"Step 1: Converting PDF to images...\")\n",
    "#             image_paths = self.pdf_to_images(pdf_path, output_dir)\n",
    "#             results['total_pages'] = len(image_paths)\n",
    "#             print(\"Step 2: Extracting text from images...\")\n",
    "#             all_text = []\n",
    "#             for i, image_path in enumerate(image_paths):\n",
    "#                 print(f\"Processing page {i + 1}/{len(image_paths)}...\")\n",
    "#                 text_results = self.extract_text_from_image(image_path, enhance_images)\n",
    "#                 filtered_text = [text for text, conf in text_results if conf >= confidence_threshold]\n",
    "#                 page_text = ' '.join(filtered_text)\n",
    "#                 all_text.append(page_text)\n",
    "#                 page_info = {'page_number': i + 1, 'image_path': image_path, 'text': page_text}\n",
    "#                 results['pages'].append(page_info)\n",
    "#             results['extracted_text'] = '\\n\\n--- Page Break ---\\n\\n'.join(all_text)\n",
    "#         except Exception as e:\n",
    "#             results['error'] = str(e)\n",
    "#         return results\n",
    "\n",
    "\n",
    "# # ChromaDB Embedding Class\n",
    "# class TextEmbedder:\n",
    "#     def __init__(self, db_path=\"./Merge_chroma_db\"):\n",
    "#         self.client = chromadb.PersistentClient(path=db_path)\n",
    "#         self.collection_name = \"pdf_embeddings\"\n",
    "#         self.collection = self.client.get_or_create_collection(\n",
    "#             name=self.collection_name,\n",
    "#             metadata={\"description\": \"PDF text embeddings\"}\n",
    "#         )\n",
    "\n",
    "#     def chunk_text(self, text, chunk_size=500, overlap=50):\n",
    "#         chunks = []\n",
    "#         words = text.split()\n",
    "#         for i in range(0, len(words), chunk_size - overlap):\n",
    "#             chunk = \" \".join(words[i:i + chunk_size])\n",
    "#             if chunk.strip():\n",
    "#                 chunks.append(chunk.strip())\n",
    "#         return chunks\n",
    "\n",
    "#     def embed_text_file(self, txt_file_path):\n",
    "#         if not os.path.exists(txt_file_path):\n",
    "#             print(f\"âŒ File not found: {txt_file_path}\")\n",
    "#             return\n",
    "#         with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             text = f.read()\n",
    "#         chunks = self.chunk_text(text)\n",
    "#         documents = chunks\n",
    "#         ids = [f\"chunk_{i+1}\" for i in range(len(chunks))]\n",
    "#         metadatas = [{\"source\": txt_file_path, \"chunk_index\": i+1} for i in range(len(chunks))]\n",
    "#         self.collection.add(documents=documents, ids=ids, metadatas=metadatas)\n",
    "#         print(f\"âœ… Successfully embedded {len(chunks)} chunks from {txt_file_path}\")\n",
    "\n",
    "#     def search_similar(self, query, n_results=3):\n",
    "#         results = self.collection.query(\n",
    "#             query_texts=[query],\n",
    "#             n_results=n_results\n",
    "#         )\n",
    "#         return results['documents'][0]\n",
    "\n",
    "\n",
    "# # Chatbot using Ollama and ChromaDB\n",
    "# class KnowledgeBase:\n",
    "#     def __init__(self, db_path=\"./Merge_chroma_db\"):\n",
    "#         self.client = chromadb.PersistentClient(path=db_path)\n",
    "#         self.collection_name = \"pdf_embeddings\"\n",
    "#         self.collection = self.client.get_or_create_collection(\n",
    "#             name=self.collection_name,\n",
    "#             metadata={\"description\": \"PDF text embeddings\"}\n",
    "#         )\n",
    "\n",
    "#     def search_similar(self, query, n_results=3):\n",
    "#         results = self.collection.query(\n",
    "#             query_texts=[query],\n",
    "#             n_results=n_results\n",
    "#         )\n",
    "#         documents = results['documents'][0]\n",
    "#         metadatas = results['metadatas'][0]\n",
    "#         return documents, metadatas\n",
    "\n",
    "\n",
    "# def chat_with_bot():\n",
    "#     kb = KnowledgeBase()\n",
    "#     system_prompt = \"\"\"\n",
    "#     You are a helpful assistant designed to assist with specific topics. \n",
    "#     Your responses should be informative, concise, and polite. \n",
    "#     You have access to a knowledge base that contains information from PDF documents, which can help provide accurate answers to user queries.\n",
    "#     If the user asks for help related to the content in the PDFs, retrieve the most relevant chunks and incorporate them into your responses.\n",
    "#     Always aim to be clear and direct in your explanations, and provide examples or context where possible.\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"ğŸ¤– Chatbot (qwen3:8b) is ready! Type 'exit' to quit.\\n\")\n",
    "#     conversation = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "#     while True:\n",
    "#         user_input = input(\"You: \")\n",
    "#         if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "#             print(\"ğŸ¤– Bot: Goodbye!\")\n",
    "#             break\n",
    "#         conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "#         kb_documents, kb_metadatas = kb.search_similar(user_input)\n",
    "#         kb_response = \"\"\n",
    "#         if kb_documents:\n",
    "#             kb_response = \"Here is some relevant information I found from the knowledge base:\\n\"\n",
    "#             for idx, document in enumerate(kb_documents):\n",
    "#                 kb_response += f\"ğŸ“„ Chunk {idx+1}: {document[:300]}...\\n\"\n",
    "#         if not kb_documents:\n",
    "#             kb_response = \"I couldn't find anything relevant in my knowledge base.\"\n",
    "#         conversation.append({\"role\": \"assistant\", \"content\": kb_response})\n",
    "#         response = ollama.chat(model=\"qwen3:8b\", messages=conversation)\n",
    "#         bot_reply = response[\"message\"][\"content\"]\n",
    "#         print(\"ğŸ¤– Bot:\", bot_reply)\n",
    "#         conversation.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     # Step 1: Extract text from PDF\n",
    "#     pdf_path = \"./New folder/privacy_policy.pdf\"  # Change this to your PDF path\n",
    "#     processor = PDFOCRProcessor(languages=['en'], gpu=False)\n",
    "#     results = processor.process_pdf(pdf_path, output_dir=\"extracted_images\", enhance_images=True, confidence_threshold=0.5)\n",
    "\n",
    "#     if 'error' not in results:\n",
    "#         # Step 2: Save the extracted text to a file\n",
    "#         with open('merge__extracted_text.txt', 'w', encoding='utf-8') as f:\n",
    "#             f.write(results['extracted_text'])\n",
    "#         print(f\"Extracted text saved to: merge__extracted_text.txt\")\n",
    "\n",
    "#         # Step 3: Embed the text file into ChromaDB\n",
    "#         embedder = TextEmbedder()\n",
    "#         embedder.embed_text_file(\"merge__extracted_text.txt\")\n",
    "\n",
    "#         # Step 4: Start the Chatbot\n",
    "#         chat_with_bot()\n",
    "#     else:\n",
    "#         print(f\"Error occurred: {results['error']}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "###\n",
    "\n",
    "import easyocr\n",
    "import ollama\n",
    "import fitz  # PyMuPDF for PDF -> images\n",
    "import os\n",
    "import shutil\n",
    "from typing import List, Tuple\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import chromadb\n",
    "from typing import List, Tuple\n",
    "from chromadb.config import Settings\n",
    "\n",
    "class PDFOCRProcessor:\n",
    "    \"\"\"PDF to Image and OCR Processor with cleanup of temporary image folder.\"\"\"\n",
    "\n",
    "    def __init__(self, languages=['en'], gpu=False, pdf_path=None, output_folder=\"pdf_images\"):\n",
    "        \"\"\"\n",
    "        Initialize the OCR Processor.\n",
    "        \n",
    "        Args:\n",
    "            languages (list): List of languages for OCR (e.g., ['en', 'es'])\n",
    "            gpu (bool): Whether to use GPU for OCR processing\n",
    "            pdf_path (str): Path to the PDF file to process\n",
    "            output_folder (str): Folder to save images temporarily\n",
    "        \"\"\"\n",
    "        print(\"Initializing EasyOCR...\")\n",
    "        self.reader = easyocr.Reader(languages, gpu=gpu)\n",
    "        print(\"EasyOCR initialized successfully!\")\n",
    "        self.pdf_path = pdf_path\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "    def pdf_to_images(self):\n",
    "        \"\"\"Convert each page of PDF to images and return paths.\"\"\"\n",
    "        if not os.path.exists(self.pdf_path):\n",
    "            raise FileNotFoundError(f\"PDF file not found: {self.pdf_path}\")\n",
    "        \n",
    "        if not os.path.exists(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "\n",
    "        doc = fitz.open(self.pdf_path)\n",
    "        image_paths = []\n",
    "        print(f\"Converting {len(doc)} pages to images...\")\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap(dpi=200)  # Higher DPI for better OCR quality\n",
    "            image_path = os.path.join(self.output_folder, f\"page_{page_num + 1}.png\")\n",
    "            pix.save(image_path)\n",
    "            image_paths.append(image_path)\n",
    "            print(f\"âœ… Page {page_num + 1} saved as {image_path}\")\n",
    "        doc.close()\n",
    "        return image_paths\n",
    "\n",
    "    def enhance_image_for_ocr(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Enhance image quality for better OCR results.\"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        denoised = cv2.fastNlMeansDenoising(gray)\n",
    "        thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        return thresh\n",
    "\n",
    "    def extract_text_from_image(self, image_path: str, enhance: bool = True) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Extract text from image using EasyOCR.\"\"\"\n",
    "        if enhance:\n",
    "            img = self.enhance_image_for_ocr(image_path)\n",
    "            results = self.reader.readtext(img)\n",
    "        else:\n",
    "            results = self.reader.readtext(image_path)\n",
    "        text_results = [(result[1], result[2]) for result in results]\n",
    "        return text_results\n",
    "\n",
    "    def cleanup_images(self):\n",
    "        \"\"\"Delete all images from the output folder after extraction.\"\"\"\n",
    "        if os.path.exists(self.output_folder):\n",
    "            shutil.rmtree(self.output_folder)\n",
    "            print(f\"ğŸ—‘ï¸ Deleted temporary folder: {self.output_folder}\")\n",
    "\n",
    "    def process_pdf(self):\n",
    "        \"\"\"Full pipeline: PDF -> images -> OCR -> Text extraction.\"\"\"\n",
    "        results = {'pdf_path': self.pdf_path, 'pages': [], 'total_pages': 0, 'extracted_text': ''}\n",
    "        try:\n",
    "            print(\"Step 1: Converting PDF to images...\")\n",
    "            image_paths = self.pdf_to_images()\n",
    "            results['total_pages'] = len(image_paths)\n",
    "            print(\"Step 2: Extracting text from images...\")\n",
    "            all_text = []\n",
    "            for i, image_path in enumerate(image_paths):\n",
    "                print(f\"Processing page {i + 1}/{len(image_paths)}...\")\n",
    "                text_results = self.extract_text_from_image(image_path, enhance=True)\n",
    "                page_text = ' '.join([text for text, conf in text_results if conf >= 0.5])\n",
    "                all_text.append(page_text)\n",
    "                page_info = {'page_number': i + 1, 'image_path': image_path, 'text': page_text}\n",
    "                results['pages'].append(page_info)\n",
    "            results['extracted_text'] = '\\n\\n--- Page Break ---\\n\\n'.join(all_text)\n",
    "\n",
    "            # Clean up temporary images after OCR extraction\n",
    "            self.cleanup_images()\n",
    "\n",
    "        except Exception as e:\n",
    "            results['error'] = str(e)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "class TextEmbedder:\n",
    "    \"\"\"Text Embedder for storing extracted text in ChromaDB.\"\"\"\n",
    "\n",
    "    def __init__(self, db_path=\"./merge__chroma_db\"):\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection_name = \"pdf_embeddings\"\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=self.collection_name,\n",
    "            metadata={\"description\": \"PDF text embeddings\"}\n",
    "        )\n",
    "\n",
    "    def chunk_text(self, text, chunk_size=500, overlap=50):\n",
    "        \"\"\"Split text into overlapping chunks.\"\"\"\n",
    "        chunks = []\n",
    "        words = text.split()\n",
    "        for i in range(0, len(words), chunk_size - overlap):\n",
    "            chunk = \" \".join(words[i:i + chunk_size])\n",
    "            if chunk.strip():\n",
    "                chunks.append(chunk.strip())\n",
    "        return chunks\n",
    "\n",
    "    def embed_text_file(self, txt_file_path):\n",
    "        \"\"\"Read text file and embed it chunk by chunk.\"\"\"\n",
    "        if not os.path.exists(txt_file_path):\n",
    "            print(f\"âŒ File not found: {txt_file_path}\")\n",
    "            return\n",
    "\n",
    "        with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        chunks = self.chunk_text(text)\n",
    "        documents = chunks\n",
    "        ids = [f\"chunk_{i+1}\" for i in range(len(chunks))]\n",
    "        metadatas = [{\"source\": txt_file_path, \"chunk_index\": i+1} for i in range(len(chunks))]\n",
    "        self.collection.add(documents=documents, ids=ids, metadatas=metadatas)\n",
    "        print(f\"âœ… Successfully embedded {len(chunks)} chunks from {txt_file_path}\")\n",
    "\n",
    "    def search_similar(self, query, n_results=3):\n",
    "        \"\"\"Search for similar chunks.\"\"\"\n",
    "        results = self.collection.query(query_texts=[query], n_results=n_results)\n",
    "        return results['documents'][0]\n",
    "\n",
    "\n",
    "class KnowledgeBase:\n",
    "    \"\"\"Knowledge base class to interact with ChromaDB for search.\"\"\"\n",
    "\n",
    "    def __init__(self, db_path=\"./merge__chroma_db\"):\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection_name = \"pdf_embeddings\"\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=self.collection_name,\n",
    "            metadata={\"description\": \"PDF text embeddings\"}\n",
    "        )\n",
    "\n",
    "    def search_similar(self, query, n_results=3):\n",
    "        \"\"\"Search for similar chunks in the ChromaDB collection.\"\"\"\n",
    "        results = self.collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        documents = results['documents'][0]\n",
    "        metadatas = results['metadatas'][0]\n",
    "        return documents, metadatas\n",
    "\n",
    "\n",
    "def chat_with_bot():\n",
    "    kb = KnowledgeBase()\n",
    "    system_prompt = \"\"\"\n",
    "    You are a helpful assistant designed to assist with specific topics. \n",
    "    Your responses should be informative, concise, and polite. \n",
    "    You have access to a knowledge base that contains information from PDF documents, which can help provide accurate answers to user queries.\n",
    "    If the user asks for help related to the content in the PDFs, retrieve the most relevant chunks and incorporate them into your responses.\n",
    "    Always aim to be clear and direct in your explanations, and provide examples or context where possible.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ğŸ¤– Chatbot (qwen3:8b) is ready! Type 'exit' to quit.\\n\")\n",
    "    conversation = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"ğŸ¤– Bot: Goodbye!\")\n",
    "            break\n",
    "        conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "        kb_documents, kb_metadatas = kb.search_similar(user_input)\n",
    "        kb_response = \"\"\n",
    "        if kb_documents:\n",
    "            kb_response = \"Here is some relevant information I found from the knowledge base:\\n\"\n",
    "            for idx, document in enumerate(kb_documents):\n",
    "                kb_response += f\"ğŸ“„ Chunk {idx+1}: {document[:300]}...\\n\"\n",
    "        if not kb_documents:\n",
    "            kb_response = \"I couldn't find anything relevant in my knowledge base.\"\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": kb_response})\n",
    "        response = ollama.chat(model=\"qwen3:8b\", messages=conversation)\n",
    "        bot_reply = response[\"message\"][\"content\"]\n",
    "        print(\"ğŸ¤– Bot:\", bot_reply)\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Step 1: Extract text from PDF\n",
    "    pdf_path = \"./New folder/privacy_policy.pdf\"  # Change this to your PDF path\n",
    "    processor = PDFOCRProcessor(pdf_path=pdf_path, languages=['en'], gpu=False, output_folder=\"pdf_images\")\n",
    "    results = processor.process_pdf()\n",
    "\n",
    "    if 'error' not in results:\n",
    "        # Step 2: Save the extracted text to a file\n",
    "        with open('merge__extracted_text.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(results['extracted_text'])\n",
    "        print(f\"Extracted text saved to: merge__extracted_text.txt\")\n",
    "\n",
    "        # Step 3: Embed the text file into ChromaDB\n",
    "        embedder = TextEmbedder()\n",
    "        embedder.embed_text_file(\"merge__extracted_text.txt\")\n",
    "\n",
    "        # Step 4: Start the Chatbot\n",
    "        chat_with_bot()\n",
    "    else:\n",
    "        print(f\"Error occurred: {results['error']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a05f14",
   "metadata": {},
   "source": [
    "## multiple pdf handeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e03cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing PDF: ./multi_pdf_test\\about_us.pdf\n",
      "Initializing EasyOCR...\n",
      "EasyOCR initialized successfully!\n",
      "Step 1: Converting PDF to images...\n",
      "Converting 4 pages to images...\n",
      "âœ… Page 1 saved as pdf_images\\page_1.png\n",
      "âœ… Page 2 saved as pdf_images\\page_2.png\n",
      "âœ… Page 3 saved as pdf_images\\page_3.png\n",
      "âœ… Page 4 saved as pdf_images\\page_4.png\n",
      "Step 2: Extracting text from images...\n",
      "Processing page 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Busra\\Melikoz\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 2/4...\n",
      "Processing page 3/4...\n",
      "Processing page 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ Deleted temporary folder: pdf_images\n",
      "Extracted text from about_us.pdf added.\n",
      "\n",
      "Processing PDF: ./multi_pdf_test\\privacy_policy.pdf\n",
      "Initializing EasyOCR...\n",
      "EasyOCR initialized successfully!\n",
      "Step 1: Converting PDF to images...\n",
      "Converting 7 pages to images...\n",
      "âœ… Page 1 saved as pdf_images\\page_1.png\n",
      "âœ… Page 2 saved as pdf_images\\page_2.png\n",
      "âœ… Page 3 saved as pdf_images\\page_3.png\n",
      "âœ… Page 4 saved as pdf_images\\page_4.png\n",
      "âœ… Page 5 saved as pdf_images\\page_5.png\n",
      "âœ… Page 6 saved as pdf_images\\page_6.png\n",
      "âœ… Page 7 saved as pdf_images\\page_7.png\n",
      "Step 2: Extracting text from images...\n",
      "Processing page 1/7...\n",
      "Processing page 2/7...\n",
      "Processing page 3/7...\n",
      "Processing page 4/7...\n",
      "Processing page 5/7...\n",
      "Processing page 6/7...\n",
      "Processing page 7/7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ Deleted temporary folder: pdf_images\n",
      "Extracted text from privacy_policy.pdf added.\n",
      "\n",
      "Processing PDF: ./multi_pdf_test\\Return Policy.pdf\n",
      "Initializing EasyOCR...\n",
      "EasyOCR initialized successfully!\n",
      "Step 1: Converting PDF to images...\n",
      "Converting 5 pages to images...\n",
      "âœ… Page 1 saved as pdf_images\\page_1.png\n",
      "âœ… Page 2 saved as pdf_images\\page_2.png\n",
      "âœ… Page 3 saved as pdf_images\\page_3.png\n",
      "âœ… Page 4 saved as pdf_images\\page_4.png\n",
      "âœ… Page 5 saved as pdf_images\\page_5.png\n",
      "Step 2: Extracting text from images...\n",
      "Processing page 1/5...\n",
      "Processing page 2/5...\n",
      "Processing page 3/5...\n",
      "Processing page 4/5...\n",
      "Processing page 5/5...\n",
      "ğŸ—‘ï¸ Deleted temporary folder: pdf_images\n",
      "Extracted text from Return Policy.pdf added.\n",
      "\n",
      "âœ… Extraction Complete! All text saved to multipdf_merge_combined_extracted_text.txt\n",
      "âœ… Successfully embedded 9 chunks from multipdf_merge_combined_extracted_text.txt\n",
      "ğŸ¤– Chatbot (qwen3:8b) is ready! Type 'exit' to quit.\n",
      "\n",
      "ğŸ¤– Bot: ğŸ“„ Chunk 4: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 5: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 6: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 7: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 8: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 9: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 10: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "\n",
      "Based on this information, here's what you need to do to request a refund:\n",
      "\n",
      "1. **Return the Product**: Ensure the product is at least 50% full and return it within 365 days of purchase. For sets, return all items in the set.\n",
      "\n",
      "2. **Include Documentation**: Attach a copy of your invoice or receipt with the returned item. Confirm the order number and the products being returned.\n",
      "\n",
      "3. **Provide Tracking Details**: If applicable, include return tracking details when submitting your request to the Customer Happiness team.\n",
      "\n",
      "4. **Wait for Refund**: The refund process typically takes 12 business days after the product is received by DECIEM. During high volume periods, this may take longer.\n",
      "\n",
      "For more details, visit the provided link or contact the Customer Happiness team.\n",
      "</think>\n",
      "\n",
      "To proceed with your refund request, follow these steps based on the information from the knowledge base:\n",
      "\n",
      "1. **Return the Product**:  \n",
      "   - Return the item **within 365 days** of purchase (at least 50% full).  \n",
      "   - For **sets** (e.g., The Ordinary No-Brainer Set), return **all items** in the set to qualify.  \n",
      "\n",
      "2. **Include Required Documents**:  \n",
      "   - Attach a **copy of your invoice/receipt** with the returned item.  \n",
      "   - Confirm your **order number** and the **products being returned**.  \n",
      "\n",
      "3. **Provide Tracking Details**:  \n",
      "   - Share return tracking information if applicable when contacting the Customer Happiness team.  \n",
      "\n",
      "4. **Refund Timeline**:  \n",
      "   - Refunds are processed within **12 business days** after DECIEM receives the returned item. Delays may occur during high-volume periods.  \n",
      "\n",
      "For further assistance, visit the provided link or contact the Customer Happiness team directly. Let me know if you need help with anything else!\n",
      "ğŸ¤– Bot: ğŸ“„ Chunk 4: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 5: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 6: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 7: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 8: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 9: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "ğŸ“„ Chunk 10: Page Break --- 8/25/25, 5.35 PM Calmly Writer Online Refunds We aim to refund you within 12 business days of the product being returned to DECIEM_ however , these times may be impacted during high volume periods . Al1 retur...\n",
      "\n",
      "Based on this information, there is no explicit mention of shipping to Bangladesh in the provided chunks. However, hereâ€™s what you can do:\n",
      "\n",
      "1. **Check Shipping Policies**: Look for details on international shipping destinations in the official website or contact the Customer Happiness team to confirm if Bangladesh is supported.  \n",
      "2. **Contact Support**: Reach out to the Customer Happiness team for clarification on shipping options to Bangladesh.  \n",
      "3. **Review Return Guidelines**: If shipping to Bangladesh is allowed, ensure you understand the return process (e.g., 365-day return window, 50% full product requirement).  \n",
      "\n",
      "For specific details, visit the provided link or contact the team directly. Let me know if you need further assistance!\n",
      "ğŸ¤– Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import fitz  # PyMuPDF for PDF -> images\n",
    "import os\n",
    "import shutil\n",
    "import ollama\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "\n",
    "\n",
    "class PDFOCRProcessor:\n",
    "    \"\"\"PDF to Image and OCR Processor with cleanup of temporary image folder.\"\"\"\n",
    "\n",
    "    def __init__(self, languages=['en'], gpu=False, pdf_path=None, output_folder=\"pdf_images\"):\n",
    "        \"\"\"\n",
    "        Initialize the OCR Processor.\n",
    "        \n",
    "        Args:\n",
    "            languages (list): List of languages for OCR (e.g., ['en', 'es'])\n",
    "            gpu (bool): Whether to use GPU for OCR processing\n",
    "            pdf_path (str): Path to the PDF file to process\n",
    "            output_folder (str): Folder to save images temporarily\n",
    "        \"\"\"\n",
    "        print(\"Initializing EasyOCR...\")\n",
    "        self.reader = easyocr.Reader(languages, gpu=gpu)\n",
    "        print(\"EasyOCR initialized successfully!\")\n",
    "        self.pdf_path = pdf_path\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "    def pdf_to_images(self):\n",
    "        \"\"\"Convert each page of PDF to images and return paths.\"\"\"\n",
    "        if not os.path.exists(self.pdf_path):\n",
    "            raise FileNotFoundError(f\"PDF file not found: {self.pdf_path}\")\n",
    "        \n",
    "        if not os.path.exists(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "\n",
    "        doc = fitz.open(self.pdf_path)\n",
    "        image_paths = []\n",
    "        print(f\"Converting {len(doc)} pages to images...\")\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap(dpi=200)  # Higher DPI for better OCR quality\n",
    "            image_path = os.path.join(self.output_folder, f\"page_{page_num + 1}.png\")\n",
    "            pix.save(image_path)\n",
    "            image_paths.append(image_path)\n",
    "            print(f\"âœ… Page {page_num + 1} saved as {image_path}\")\n",
    "        doc.close()\n",
    "        return image_paths\n",
    "\n",
    "    def enhance_image_for_ocr(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Enhance image quality for better OCR results.\"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        denoised = cv2.fastNlMeansDenoising(gray)\n",
    "        thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        return thresh\n",
    "\n",
    "    def extract_text_from_image(self, image_path: str, enhance: bool = True) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Extract text from image using EasyOCR.\"\"\"\n",
    "        if enhance:\n",
    "            img = self.enhance_image_for_ocr(image_path)\n",
    "            results = self.reader.readtext(img)\n",
    "        else:\n",
    "            results = self.reader.readtext(image_path)\n",
    "        text_results = [(result[1], result[2]) for result in results]\n",
    "        return text_results\n",
    "\n",
    "    def cleanup_images(self):\n",
    "        \"\"\"Delete all images from the output folder after extraction.\"\"\"\n",
    "        if os.path.exists(self.output_folder):\n",
    "            shutil.rmtree(self.output_folder)\n",
    "            print(f\"ğŸ—‘ï¸ Deleted temporary folder: {self.output_folder}\")\n",
    "\n",
    "    def process_pdf(self):\n",
    "        \"\"\"Full pipeline: PDF -> images -> OCR -> Text extraction.\"\"\"\n",
    "        results = {'pdf_path': self.pdf_path, 'pages': [], 'total_pages': 0, 'extracted_text': ''}\n",
    "        try:\n",
    "            print(\"Step 1: Converting PDF to images...\")\n",
    "            image_paths = self.pdf_to_images()\n",
    "            results['total_pages'] = len(image_paths)\n",
    "            print(\"Step 2: Extracting text from images...\")\n",
    "            all_text = []\n",
    "            for i, image_path in enumerate(image_paths):\n",
    "                print(f\"Processing page {i + 1}/{len(image_paths)}...\")\n",
    "                text_results = self.extract_text_from_image(image_path, enhance=True)\n",
    "                page_text = ' '.join([text for text, conf in text_results if conf >= 0.5])\n",
    "                all_text.append(page_text)\n",
    "                page_info = {'page_number': i + 1, 'image_path': image_path, 'text': page_text}\n",
    "                results['pages'].append(page_info)\n",
    "            results['extracted_text'] = '\\n\\n--- Page Break ---\\n\\n'.join(all_text)\n",
    "\n",
    "            # Clean up temporary images after OCR extraction\n",
    "            self.cleanup_images()\n",
    "\n",
    "        except Exception as e:\n",
    "            results['error'] = str(e)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "class TextEmbedder:\n",
    "    \"\"\"Text Embedder for storing extracted text in ChromaDB.\"\"\"\n",
    "\n",
    "    def __init__(self, db_path=\"./multipdf_merge_chroma_db\"):\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection_name = \"pdf_embeddings\"\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=self.collection_name,\n",
    "            metadata={\"description\": \"PDF text embeddings\"}\n",
    "        )\n",
    "\n",
    "    def chunk_text(self, text, chunk_size=500, overlap=50):\n",
    "        \"\"\"Split text into overlapping chunks.\"\"\"\n",
    "        chunks = []\n",
    "        words = text.split()\n",
    "        for i in range(0, len(words), chunk_size - overlap):\n",
    "            chunk = \" \".join(words[i:i + chunk_size])\n",
    "            if chunk.strip():\n",
    "                chunks.append(chunk.strip())\n",
    "        return chunks\n",
    "\n",
    "    def embed_text_file(self, txt_file_path):\n",
    "        \"\"\"Read text file and embed it chunk by chunk.\"\"\"\n",
    "        if not os.path.exists(txt_file_path):\n",
    "            print(f\"âŒ File not found: {txt_file_path}\")\n",
    "            return\n",
    "\n",
    "        with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        chunks = self.chunk_text(text)\n",
    "        documents = chunks\n",
    "        ids = [f\"chunk_{i+1}\" for i in range(len(chunks))]\n",
    "        metadatas = [{\"source\": txt_file_path, \"chunk_index\": i+1} for i in range(len(chunks))]\n",
    "        self.collection.add(documents=documents, ids=ids, metadatas=metadatas)\n",
    "        print(f\"âœ… Successfully embedded {len(chunks)} chunks from {txt_file_path}\")\n",
    "\n",
    "    def search_similar(self, query, n_results=3):\n",
    "        \"\"\"Search for similar chunks.\"\"\"\n",
    "        results = self.collection.query(query_texts=[query], n_results=n_results)\n",
    "        return results['documents'][0]\n",
    "\n",
    "\n",
    "class KnowledgeBase:\n",
    "    \"\"\"Knowledge base class to interact with ChromaDB for search.\"\"\"\n",
    "\n",
    "    def __init__(self, db_path=\"./multipdf_merge_chroma_db\"):\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection_name = \"pdf_embeddings\"\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=self.collection_name,\n",
    "            metadata={\"description\": \"PDF text embeddings\"}\n",
    "        )\n",
    "\n",
    "    def search_similar(self, query, n_results=3):\n",
    "        \"\"\"Search for similar chunks in the ChromaDB collection.\"\"\"\n",
    "        results = self.collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        documents = results['documents'][0]\n",
    "        metadatas = results['metadatas'][0]\n",
    "        return documents, metadatas\n",
    "\n",
    "\n",
    "def chat_with_bot():\n",
    "    kb = KnowledgeBase()\n",
    "    system_prompt = \"\"\"\n",
    "    You are a helpful assistant designed to assist with specific topics. \n",
    "    Your responses should be informative, concise, and polite. \n",
    "    You have access to a knowledge base that contains information from PDF documents, which can help provide accurate answers to user queries.\n",
    "    If the user asks for help related to the content in the PDFs, retrieve the most relevant chunks and incorporate them into your responses.\n",
    "    Always aim to be clear and direct in your explanations, and provide examples or context where possible.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ğŸ¤– Chatbot (qwen3:8b) is ready! Type 'exit' to quit.\\n\")\n",
    "    conversation = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"ğŸ¤– Bot: Goodbye!\")\n",
    "            break\n",
    "        conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "        kb_documents, kb_metadatas = kb.search_similar(user_input)\n",
    "        kb_response = \"\"\n",
    "        if kb_documents:\n",
    "            kb_response = \"Here is some relevant information I found from the knowledge base:\\n\"\n",
    "            for idx, document in enumerate(kb_documents):\n",
    "                kb_response += f\"ğŸ“„ Chunk {idx+1}: {document[:300]}...\\n\"\n",
    "        if not kb_documents:\n",
    "            kb_response = \"I couldn't find anything relevant in my knowledge base.\"\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": kb_response})\n",
    "        response = ollama.chat(model=\"qwen3:8b\", messages=conversation)\n",
    "        bot_reply = response[\"message\"][\"content\"]\n",
    "        print(\"ğŸ¤– Bot:\", bot_reply)\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "\n",
    "\n",
    "def process_multiple_pdfs_in_folder(pdf_folder_path):\n",
    "    \"\"\"Process all PDFs in the specified folder.\"\"\"\n",
    "    all_extracted_text = \"\"\n",
    "    \n",
    "    # Loop through all PDF files in the folder\n",
    "    for pdf_file in os.listdir(pdf_folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(pdf_folder_path, pdf_file)\n",
    "            print(f\"\\nProcessing PDF: {pdf_path}\")\n",
    "            \n",
    "            \n",
    "            processor = PDFOCRProcessor(pdf_path=pdf_path, languages=['en'], gpu=False, output_folder=\"pdf_images\")\n",
    "            results = processor.process_pdf()\n",
    "\n",
    "            if 'error' not in results:\n",
    "                \n",
    "                all_extracted_text += f\"\\n\\n--- Extracted Text from {pdf_file} ---\\n\\n\"\n",
    "                all_extracted_text += results['extracted_text']\n",
    "                print(f\"Extracted text from {pdf_file} added.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Error occurred while processing {pdf_file}: {results['error']}\")\n",
    "\n",
    "    # Save the combined extracted text to a file\n",
    "    with open('multipdf_merge_combined_extracted_text.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(all_extracted_text)\n",
    "    print(f\"\\nâœ… Extraction Complete! All text saved to multipdf_merge_combined_extracted_text.txt\")\n",
    "\n",
    "    return 'multipdf_merge_combined_extracted_text.txt'\n",
    "\n",
    "\n",
    "def main():\n",
    "    pdf_folder_path = \"./multi_pdf_test\"  # Change this to your folder path with PDFs\n",
    "    \n",
    "    # Step 1: Process all PDFs in the folder and extract text\n",
    "    combined_txt_file = process_multiple_pdfs_in_folder(pdf_folder_path)\n",
    "\n",
    "    # Step 2: Embed the combined extracted text file into ChromaDB\n",
    "    embedder = TextEmbedder()\n",
    "    embedder.embed_text_file(combined_txt_file)\n",
    "\n",
    "    # Step 3: Start the Chatbot\n",
    "    chat_with_bot()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
